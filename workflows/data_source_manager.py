#!/usr/bin/env python3
"""
æ•°æ®æºç®¡ç†å™¨ v2.0 â€” æŠ•èµ„Agentå¤šæºæ•°æ®èšåˆå±‚

æ¶æ„:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DataSourceManager                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ AlphaVantage  â”‚  â”‚  FRED    â”‚  â”‚ AkShare  â”‚              â”‚
â”‚  â”‚ (ä¸»æ•°æ®æº)    â”‚  â”‚(å®è§‚æ•°æ®) â”‚  â”‚(ä¸­å›½å¸‚åœº) â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                â”‚
â”‚  â”‚ yfinance  â”‚  â† é™çº§å¤‡ç”¨ï¼ˆAVå¤±è´¥æ—¶ä½¿ç”¨ï¼‰                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              å…¨å±€ç¼“å­˜å±‚ (Session Cache)                 â”‚ â”‚
â”‚  â”‚     å»é‡ä¸‹è½½ Â· è·¨Skillå…±äº« Â· å¤±è´¥é™çº§ Â· é™æµæ§åˆ¶        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ•°æ®æºä¼˜å…ˆçº§:
  - è¡Œæƒ…æ•°æ®: Alpha Vantage (ä¸») â†’ yfinance (é™çº§) â†’ ç¼“å­˜
  - å®è§‚æ•°æ®: FRED (ä¸»)
  - Aè‚¡/æ¸¯è‚¡: AkShare (ä¸»)
  - æŠ€æœ¯æŒ‡æ ‡: æœ¬åœ°è®¡ç®— (ä¸») â†’ Alpha Vantage API (å¤‡ç”¨)
"""

import os
import sys
import json
import time
import random
import requests
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from typing import Optional, Dict, List, Any, Tuple

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SSLè¯ä¹¦ä¿®å¤ï¼ˆmacOS Python 3.x å¸¸è§é—®é¢˜ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
try:
    import certifi
    os.environ.setdefault('SSL_CERT_FILE', certifi.where())
except ImportError:
    pass


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Alpha Vantage é…ç½®ä¸æ ¸å¿ƒè¯·æ±‚å±‚
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ALPHA_VANTAGE_KEY = os.environ.get('ALPHA_VANTAGE_KEY', '2DY8F4CY466WAT7U')
AV_BASE_URL = 'https://www.alphavantage.co/query'
AV_CALL_DELAY = 5.0  # å…è´¹ç‰ˆé™åˆ¶ï¼šçº¦25æ¬¡/åˆ†é’Ÿï¼Œä¿å®ˆé—´éš”5ç§’ï¼ˆé¿å…è§¦å‘é™æµï¼‰

# æŒ‡æ•° â†’ ETF æ˜ å°„ï¼ˆAlpha Vantageä¸æ”¯æŒæŒ‡æ•°tickerï¼Œç”¨ETFä»£ç†ï¼‰
INDEX_TO_ETF = {
    '^GSPC': 'SPY',    # S&P 500
    '^IXIC': 'QQQ',    # NASDAQ
    '^DJI': 'DIA',     # é“ç¼æ–¯
    '^RUT': 'IWM',     # ç½—ç´ 2000
    '^VIX': 'VIXY',    # VIXï¼ˆè¿‘ä¼¼ï¼‰
    '^VIX9D': None,    # æ— ETFä»£ç†
    '^HSI': 'EWH',     # æ’ç”Ÿ
    '^HSTECH': None,   # æ’ç”Ÿç§‘æŠ€æ— ç›´æ¥ETF
    '^N225': 'EWJ',    # æ—¥ç»
    '^FTSE': 'EWU',    # è‹±å›½
    '^GDAXI': 'EWG',   # å¾·å›½
    '^STOXX50E': 'FEZ', # æ¬§æ´²
    '^TNX': None,       # 10Yæ”¶ç›Šç‡ï¼Œç”¨FREDæ›¿ä»£
    '^FVX': None,       # 5Yæ”¶ç›Šç‡
    '^IRX': None,       # 3Mæ”¶ç›Šç‡
}

# æŒ‡æ•°ticker â†’ AkShareä¸œæ–¹è´¢å¯Œå…¨çƒæŒ‡æ•°ä»£ç ï¼ˆindex_global_spot_emï¼‰
# ç”¨äºè·å–çœŸå®æŒ‡æ•°ç‚¹ä½ï¼ˆè€ŒéETFä»£ç†ä»·æ ¼ï¼‰
INDEX_TO_AKSHARE_GLOBAL = {
    '^GSPC': 'SPX',     # æ ‡æ™®500
    '^IXIC': 'NDX',     # çº³æ–¯è¾¾å…‹
    '^DJI': 'DJIA',     # é“ç¼æ–¯
    '^HSI': 'HSI',      # æ’ç”ŸæŒ‡æ•°
    '^N225': 'N225',    # æ—¥ç»225
    '^FTSE': 'FTSE',    # è‹±å›½å¯Œæ—¶100
    '^GDAXI': 'GDAXI',  # å¾·å›½DAX30
    '^STOXX50E': 'SX5E', # æ¬§æ´²æ–¯æ‰˜å…‹50
}

# è¡¥å……æŒ‡æ•°: AkShareå…¨çƒæŒ‡æ•°åˆ—è¡¨ä¸­ç¼ºå¤±çš„ï¼Œé€šè¿‡Google Financeç½‘é¡µè·å–
# æ ¼å¼: ticker â†’ (Google Finance symbol, exchange)
INDEX_GOOGLE_FINANCE_FALLBACK = {
    '^RUT': ('RUT', 'INDEXRUSSELL'),   # ç½—ç´ 2000
    '^VIX': ('VIX', 'INDEXCBOE'),      # VIXææ…ŒæŒ‡æ•°
}

# åŠ å¯†è´§å¸ ticker æ˜ å°„ï¼ˆyfinanceæ ¼å¼ â†’ AVæ ¼å¼ï¼‰
CRYPTO_MAP = {
    'BTC-USD': 'BTC',
    'ETH-USD': 'ETH',
    'SOL-USD': 'SOL',
}

# æ±‡ç‡ ticker æ˜ å°„
FX_MAP = {
    'CNY=X': ('USD', 'CNY'),
}

# AkShareç¾è‚¡ ticker â†’ ä¸œæ–¹è´¢å¯Œä»£ç æ˜ å°„
# æ ¼å¼: "105.XXX"(NASDAQ ETF/è‚¡ç¥¨) "106.XXX"(ç¾è‚¡æ­£è‚¡) "107.XXX"(NYSE/ARCA ETF)
AKSHARE_US_PREFIX = {
    # â•â•â• ETF: NASDAQä¸Šå¸‚ (105) â•â•â•
    'QQQ': '105.QQQ', 'TLT': '105.TLT', 'IEF': '105.IEF', 'SHY': '105.SHY',
    'PDBC': '105.PDBC', 'MCHI': '105.MCHI',
    # â•â•â• ETF: NYSE/ARCAä¸Šå¸‚ (107) â•â•â•
    'SPY': '107.SPY', 'DIA': '107.DIA', 'IWM': '107.IWM',
    'HYG': '107.HYG', 'LQD': '107.LQD', 'UUP': '107.UUP', 'GLD': '107.GLD',
    'SLV': '107.SLV', 'GDX': '107.GDX', 'USO': '107.USO', 'CPER': '107.CPER',
    'DBA': '107.DBA', 'BKLN': '107.BKLN', 'KRE': '107.KRE',
    'KWEB': '107.KWEB', 'FXI': '107.FXI', 'EWH': '107.EWH',
    'EWJ': '107.EWJ', 'EWU': '107.EWU', 'EWG': '107.EWG', 'FEZ': '107.FEZ',
    'VIXY': '107.VIXY', 'FXY': '107.FXY', 'FXE': '107.FXE',
    'USHY': '107.USHY', 'UNG': '107.UNG',
    # â•â•â• ç¾è‚¡æ­£è‚¡ (106=ä¸œæ–¹è´¢å¯Œç¾è‚¡æ­£è‚¡å‰ç¼€) â•â•â•
    # NASDAQä¸Šå¸‚ä¸ªè‚¡
    'AAPL': '105.AAPL', 'MSFT': '105.MSFT', 'AMZN': '105.AMZN', 'GOOGL': '105.GOOGL',
    'META': '105.META', 'NVDA': '105.NVDA', 'TSLA': '105.TSLA', 'AMD': '105.AMD',
    'NFLX': '105.NFLX', 'AVGO': '105.AVGO', 'COST': '105.COST', 'ADBE': '105.ADBE',
    'INTC': '105.INTC', 'QCOM': '105.QCOM', 'PYPL': '105.PYPL',
    'TXN': '105.TXN', 'MU': '105.MU', 'AMAT': '105.AMAT', 'LRCX': '105.LRCX',
    'KLAC': '105.KLAC', 'MRVL': '105.MRVL', 'SNPS': '105.SNPS', 'CDNS': '105.CDNS',
    'PANW': '105.PANW', 'CRWD': '105.CRWD', 'ABNB': '105.ABNB', 'COIN': '105.COIN',
    'PDD': '105.PDD',
    # NYSE/å…¶ä»–äº¤æ˜“æ‰€æ­£è‚¡ â†’ ç”¨106å‰ç¼€ï¼ˆä¸œæ–¹è´¢å¯Œç¾è‚¡æ­£è‚¡æ ‡å‡†æ ¼å¼ï¼‰
    'JPM': '106.JPM', 'V': '106.V', 'MA': '106.MA', 'BAC': '106.BAC',
    'WMT': '106.WMT', 'JNJ': '106.JNJ', 'PG': '106.PG', 'UNH': '106.UNH',
    'HD': '106.HD', 'DIS': '106.DIS', 'BA': '106.BA', 'GS': '106.GS',
    'XOM': '106.XOM', 'CVX': '106.CVX',
    'BRK-B': '106.BRK_B',  # ä¸œæ–¹è´¢å¯Œç”¨ä¸‹åˆ’çº¿æ›¿ä»£æ¨ªæ 
    'TSM': '106.TSM', 'LLY': '106.LLY', 'NVO': '106.NVO',
    'BABA': '106.BABA', 'CRM': '106.CRM',
    # TCEHY(è…¾è®¯ADR) = OTCäº¤æ˜“ï¼Œä¸œæ–¹è´¢å¯Œæ— æ•°æ®ï¼Œéœ€CoinGeckoæˆ–å…¶ä»–æº
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ•°æ®æºé…ç½®
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

FRED_API_KEY = os.environ.get('FRED_API_KEY', '78b890270efd7d6c2d9365b0c658adcc')

# é™æµé…ç½®
FRED_CALL_DELAY = 0.5
AKSHARE_CALL_DELAY = 0.5
YFINANCE_BATCH_DELAY = 2.0
YFINANCE_TICKER_INFO_DELAY = 2.0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ•°æ®ç»“æ„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class DataPoint:
    """å•ä¸ªæ•°æ®ç‚¹"""
    source: str
    value: float
    timestamp: str
    unit: str = ""
    note: str = ""

@dataclass
class MacroData:
    """å®è§‚ç»æµæ•°æ®åŒ…"""
    fed_funds_rate: Optional[float] = None
    cpi_yoy: Optional[float] = None
    core_pce: Optional[float] = None
    unemployment: Optional[float] = None
    gdp_growth: Optional[float] = None
    us10y_yield: Optional[float] = None
    us2y_yield: Optional[float] = None
    us2s10s_spread: Optional[float] = None
    us3m10s_spread: Optional[float] = None
    hy_spread: Optional[float] = None
    fed_balance_sheet: Optional[float] = None
    tga_balance: Optional[float] = None
    on_rrp: Optional[float] = None
    net_liquidity: Optional[float] = None
    m2_supply: Optional[float] = None
    mortgage_rate_30y: Optional[float] = None
    initial_claims: Optional[float] = None
    dxy_index: Optional[float] = None
    sofr: Optional[float] = None
    move_index: Optional[float] = None
    source: str = ""
    last_updated: str = ""
    raw_data: dict = field(default_factory=dict)

@dataclass
class ChinaMarketData:
    """ä¸­å›½å¸‚åœºæ•°æ®åŒ…ï¼ˆAkShareï¼‰"""
    sh_index: Optional[float] = None
    sz_index: Optional[float] = None
    cyb_index: Optional[float] = None
    hs300: Optional[float] = None
    northbound_flow: Optional[float] = None
    southbound_flow: Optional[float] = None
    ah_premium_index: Optional[float] = None
    cny_usd: Optional[float] = None
    shibor_overnight: Optional[float] = None
    social_financing: Optional[float] = None
    margin_balance: Optional[float] = None
    source: str = ""
    last_updated: str = ""
    raw_data: dict = field(default_factory=dict)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ ¸å¿ƒ: DataSourceManager
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DataSourceManager:
    """
    å¤šæºæ•°æ®èšåˆç®¡ç†å™¨ v2.0 â€” Alpha Vantage ä¼˜å…ˆ

    åŠŸèƒ½:
    1. Alpha Vantage ä¸ºä¸»æ•°æ®æºï¼ˆè¡Œæƒ…/åŸºæœ¬é¢/åŠ å¯†/æ±‡ç‡ï¼‰
    2. FRED å®è§‚æ•°æ®ï¼ˆåˆ©ç‡/CPI/GDP/å‡€æµåŠ¨æ€§ï¼‰
    3. AkShare ä¸­å›½å¸‚åœºæ•°æ®
    4. yfinance ä½œä¸ºé™çº§å¤‡ç”¨
    5. å…¨å±€ç¼“å­˜ + é™æµæ§åˆ¶
    """

    def __init__(self, config: dict = None):
        self.config = config or {}
        self._batch_cache: Dict[str, Any] = {}          # batch_key -> DataFrame
        self._info_cache: Dict[str, dict] = {}           # ticker -> info dict
        self._fred_cache: Dict[str, Any] = {}            # series_id -> value
        self._akshare_cache: Dict[str, Any] = {}         # data_key -> value
        self._av_cache: Dict[str, Any] = {}              # AVä¸“ç”¨ç¼“å­˜
        self._macro_data: Optional[MacroData] = None
        self._china_data: Optional[ChinaMarketData] = None
        self._fear_greed: Optional[dict] = None
        self._last_api_call: Dict[str, float] = {}
        self._stats = {'av_calls': 0, 'av_cache_hits': 0,
                       'yf_downloads': 0, 'yf_cache_hits': 0,
                       'fred_calls': 0, 'akshare_calls': 0,
                       'errors': 0}
        self._av_rate_limited = False   # AVå…¨å±€é™æµæ ‡è®°
        self._av_consecutive_limits = 0  # AVè¿ç»­é™æµè®¡æ•°
        self._yf_available = None        # yfinanceå¯ç”¨æ€§ï¼ˆNone=æœªæ£€æµ‹, True/Falseï¼‰
        self._akshare_failures = {}      # AkShareå¤±è´¥è®°å½•

        # HTTP Session
        self._session = requests.Session()
        self._session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
        })

        # é¢„å®šä¹‰éœ€è¦é¢„åŠ è½½çš„tickeråˆ†ç»„ï¼ˆè¦†ç›–æ‰€æœ‰10ä¸ªSkillçš„æ ¸å¿ƒéœ€æ±‚ï¼‰
        # AVå…è´¹ç‰ˆé™åˆ¶ï¼š25æ¬¡/åˆ†é’Ÿï¼Œ500æ¬¡/å¤©
        # AVé™æµåè‡ªåŠ¨é™çº§ä¸ºyfinanceæ‰¹é‡è·å–
        self._preload_groups = {
            'indices': '^GSPC ^IXIC ^DJI ^VIX ^VIX9D ^HSI ^HSTECH ^RUT ^N225 ^FTSE ^GDAXI ^STOXX50E',
            'crypto': 'BTC-USD ETH-USD',
            'macro_bonds': 'TLT IEF SHY HYG LQD UUP FXY GLD',
            'commodities': 'USO SLV GDX CPER DBA PDBC',
            'credit': 'BKLN KRE',
            'china_etf': 'KWEB FXI MCHI EWH CNY=X',
            'market_etf': 'SPY QQQ',
        }

    # â”€â”€â”€ é™æµæ§åˆ¶ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _rate_limit(self, api_name: str, min_interval: float):
        """ç¡®ä¿APIè°ƒç”¨é—´éš”ä¸å°äºmin_intervalç§’"""
        last = self._last_api_call.get(api_name, 0)
        elapsed = time.time() - last
        if elapsed < min_interval:
            time.sleep(min_interval - elapsed)
        self._last_api_call[api_name] = time.time()

    # â”€â”€â”€ Alpha Vantage æ ¸å¿ƒè¯·æ±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _av_request(self, params: dict, max_retries: int = 3) -> Optional[dict]:
        """Alpha Vantage API ç»Ÿä¸€è¯·æ±‚ï¼ˆå¸¦é™æµ+é‡è¯•+ç¼“å­˜+å…¨å±€é™æµçŸ­è·¯ï¼‰"""
        if not ALPHA_VANTAGE_KEY:
            return None

        # å…¨å±€é™æµçŸ­è·¯ï¼šè¿ç»­3æ¬¡é™æµåè·³è¿‡AV
        if self._av_rate_limited:
            return None

        params['apikey'] = ALPHA_VANTAGE_KEY
        cache_key = json.dumps(params, sort_keys=True)

        if cache_key in self._av_cache:
            self._stats['av_cache_hits'] += 1
            return self._av_cache[cache_key]

        self._rate_limit('alpha_vantage', AV_CALL_DELAY)

        for attempt in range(max_retries):
            try:
                resp = self._session.get(AV_BASE_URL, params=params, timeout=20)
                data = resp.json()

                # æ£€æŸ¥é™æµï¼ˆNoteå­—æ®µ â€” åˆ†é’Ÿçº§é™æµï¼‰
                if 'Note' in data and 'call frequency' in data.get('Note', '').lower():
                    self._av_consecutive_limits += 1
                    if self._av_consecutive_limits >= 2:
                        self._av_rate_limited = True
                        print(f"    ğŸš« AVè¿ç»­{self._av_consecutive_limits}æ¬¡é™æµï¼Œè·³è¿‡æ‰€æœ‰AVè¯·æ±‚")
                        return None
                    if attempt < max_retries - 1:
                        wait = 12 + random.uniform(1, 3)
                        print(f"    ğŸš« AVé™æµï¼Œé€€é¿{wait:.0f}ç§’...")
                        time.sleep(wait)
                        continue
                    else:
                        return None

                # æ£€æŸ¥é”™è¯¯
                if 'Error Message' in data:
                    print(f"    âš ï¸ AVé”™è¯¯: {data['Error Message'][:60]}")
                    return None

                # æ£€æŸ¥ç©ºå“åº”æˆ–ä¿¡æ¯æ¶ˆæ¯ï¼ˆé€šå¸¸æ˜¯é™æµï¼‰
                if 'Information' in data:
                    info_msg = data['Information']
                    if 'standard API rate limit' in info_msg or 'call frequency' in info_msg.lower():
                        # æ—¥é™é¢å·²ç”¨å®Œï¼Œç›´æ¥æ ‡è®°å…¨å±€é™æµï¼ˆä¸å†é‡è¯•ï¼‰
                        self._av_rate_limited = True
                        print(f"    ğŸš« AVæ—¥é™é¢å·²ç”¨å®Œï¼Œè·³è¿‡æ‰€æœ‰AVè¯·æ±‚")
                        return None
                    print(f"    âš ï¸ AVä¿¡æ¯: {info_msg[:60]}")
                    return None

                # æˆåŠŸè·å–æ•°æ®ï¼Œé‡ç½®è¿ç»­é™æµè®¡æ•°
                self._av_consecutive_limits = 0
                self._av_cache[cache_key] = data
                self._stats['av_calls'] += 1
                return data

            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    time.sleep(2 * (attempt + 1))
                else:
                    print(f"    âŒ AVè¯·æ±‚è¶…æ—¶")
                    self._stats['errors'] += 1
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(2 * (attempt + 1))
                else:
                    print(f"    âŒ AVè¯·æ±‚å¤±è´¥: {e}")
                    self._stats['errors'] += 1
        return None

    def _av_get_daily(self, symbol: str, outputsize: str = 'compact') -> Optional[dict]:
        """è·å– TIME_SERIES_DAILY æ•°æ®"""
        return self._av_request({
            'function': 'TIME_SERIES_DAILY',
            'symbol': symbol,
            'outputsize': outputsize,
        })

    def _av_get_crypto_daily(self, symbol: str) -> Optional[dict]:
        """è·å– DIGITAL_CURRENCY_DAILY æ•°æ®"""
        return self._av_request({
            'function': 'DIGITAL_CURRENCY_DAILY',
            'symbol': symbol,
            'market': 'USD',
        })

    def _av_get_fx_daily(self, from_sym: str, to_sym: str) -> Optional[dict]:
        """è·å– FX_DAILY æ•°æ®"""
        return self._av_request({
            'function': 'FX_DAILY',
            'from_symbol': from_sym,
            'to_symbol': to_sym,
            'outputsize': 'compact',
        })

    def _av_get_global_quote(self, symbol: str) -> Optional[dict]:
        """è·å– GLOBAL_QUOTE (æœ€æ–°ä»·)"""
        return self._av_request({
            'function': 'GLOBAL_QUOTE',
            'symbol': symbol,
        })

    def _av_get_overview(self, symbol: str) -> Optional[dict]:
        """è·å– OVERVIEW (å…¬å¸åŸºæœ¬é¢)"""
        return self._av_request({
            'function': 'OVERVIEW',
            'symbol': symbol,
        })

    # â”€â”€â”€ Alpha Vantage â†’ pandas DataFrame è½¬æ¢ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _av_daily_to_df(self, data: dict, ticker: str) -> Any:
        """å°†AV TIME_SERIES_DAILYå“åº”è½¬ä¸ºä¸yfinanceå…¼å®¹çš„pandas DataFrame"""
        import pandas as pd
        import numpy as np

        ts_key = 'Time Series (Daily)'
        if ts_key not in data:
            return None

        ts = data[ts_key]
        rows = []
        for date_str, vals in ts.items():
            rows.append({
                'Date': pd.Timestamp(date_str),
                'Open': float(vals.get('1. open', 0)),
                'High': float(vals.get('2. high', 0)),
                'Low': float(vals.get('3. low', 0)),
                'Close': float(vals.get('4. close', 0)),
                'Volume': int(float(vals.get('5. volume', 0))),
            })

        if not rows:
            return None

        df = pd.DataFrame(rows)
        df.set_index('Date', inplace=True)
        df.sort_index(inplace=True)
        return df

    def _av_crypto_to_df(self, data: dict, ticker: str) -> Any:
        """å°†AV DIGITAL_CURRENCY_DAILYå“åº”è½¬ä¸ºpandas DataFrame"""
        import pandas as pd

        ts_key = 'Time Series (Digital Currency Daily)'
        if ts_key not in data:
            return None

        ts = data[ts_key]
        rows = []
        for date_str, vals in ts.items():
            # AVåŠ å¯†è´§å¸å­—æ®µåå¯èƒ½å› ç‰ˆæœ¬ä¸åŒè€Œå˜åŒ–:
            # æ—§ç‰ˆ: '4. close'  æ–°ç‰ˆ: '4a. close (USD)'
            close_val = vals.get('4a. close (USD)') or vals.get('4. close') or 0
            open_val = vals.get('1a. open (USD)') or vals.get('1. open') or 0
            high_val = vals.get('2a. high (USD)') or vals.get('2. high') or 0
            low_val = vals.get('3a. low (USD)') or vals.get('3. low') or 0
            vol_val = vals.get('5. volume') or 0
            rows.append({
                'Date': pd.Timestamp(date_str),
                'Open': float(open_val),
                'High': float(high_val),
                'Low': float(low_val),
                'Close': float(close_val),
                'Volume': float(vol_val),
            })

        if not rows:
            return None

        df = pd.DataFrame(rows)
        df.set_index('Date', inplace=True)
        df.sort_index(inplace=True)
        return df

    def _av_fx_to_df(self, data: dict, ticker: str) -> Any:
        """å°†AV FX_DAILYå“åº”è½¬ä¸ºpandas DataFrame"""
        import pandas as pd

        ts_key = 'Time Series FX (Daily)'
        if ts_key not in data:
            return None

        ts = data[ts_key]
        rows = []
        for date_str, vals in ts.items():
            close = float(vals.get('4. close', 0))
            rows.append({
                'Date': pd.Timestamp(date_str),
                'Open': float(vals.get('1. open', 0)),
                'High': float(vals.get('2. high', 0)),
                'Low': float(vals.get('3. low', 0)),
                'Close': close,
                'Volume': 0,
            })

        if not rows:
            return None

        df = pd.DataFrame(rows)
        df.set_index('Date', inplace=True)
        df.sort_index(inplace=True)
        return df

    # â”€â”€â”€ ä¸»è¦æ•°æ®è·å–æ¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _fetch_single_ticker_av(self, ticker: str) -> Any:
        """ç”¨Alpha Vantageè·å–å•ä¸ªtickerçš„DataFrame"""
        # åŠ å¯†è´§å¸
        if ticker in CRYPTO_MAP:
            av_symbol = CRYPTO_MAP[ticker]
            data = self._av_get_crypto_daily(av_symbol)
            if data:
                return self._av_crypto_to_df(data, ticker)
            return None

        # æ±‡ç‡
        if ticker in FX_MAP:
            from_sym, to_sym = FX_MAP[ticker]
            data = self._av_get_fx_daily(from_sym, to_sym)
            if data:
                return self._av_fx_to_df(data, ticker)
            return None

        # æŒ‡æ•° â†’ ETFä»£ç†
        av_symbol = ticker
        if ticker in INDEX_TO_ETF:
            etf = INDEX_TO_ETF[ticker]
            if etf is None:
                return None  # æ— ETFä»£ç†
            av_symbol = etf

        # æ™®é€šè‚¡ç¥¨/ETF
        data = self._av_get_daily(av_symbol)
        if data:
            return self._av_daily_to_df(data, ticker)
        return None

    def download_prices(self, tickers: str, period: str = "3mo",
                        interval: str = "1d", max_retries: int = 3) -> Any:
        """
        ç»Ÿä¸€çš„ä»·æ ¼ä¸‹è½½æ¥å£ï¼ˆAlpha Vantageä¼˜å…ˆ â†’ yfinanceé™çº§ï¼‰

        å…¼å®¹yfinanceçš„è°ƒç”¨æ ¼å¼ï¼Œè¿”å›pandas DataFrame:
        - å•ticker: è¿”å›å¸¦Dateç´¢å¼•çš„DataFrame (Open/High/Low/Close/Volume)
        - å¤šticker: è¿”å›MultiIndex DataFrame
        """
        import pandas as pd

        ticker_list = sorted(tickers.strip().split())
        batch_key = f"{'|'.join(ticker_list)}|{period}|{interval}"

        # ç²¾ç¡®åŒ¹é…ç¼“å­˜
        if batch_key in self._batch_cache:
            self._stats['av_cache_hits'] += 1
            return self._batch_cache[batch_key]

        # å­é›†ç¼“å­˜å‘½ä¸­
        ticker_set = set(ticker_list)
        for cached_key, cached_data in self._batch_cache.items():
            cached_parts = cached_key.rsplit('|', 2)
            if len(cached_parts) == 3 and cached_parts[1] == period and cached_parts[2] == interval:
                cached_tickers = set(cached_parts[0].split('|'))
                if ticker_set.issubset(cached_tickers):
                    try:
                        if isinstance(cached_data.columns, pd.MultiIndex):
                            available = set(cached_data.columns.get_level_values(1).unique())
                            found = ticker_set & available
                            if found:
                                if len(ticker_list) == 1:
                                    t = ticker_list[0]
                                    if t in available:
                                        subset = cached_data.xs(t, level=1, axis=1)
                                        self._batch_cache[batch_key] = subset
                                        self._stats['av_cache_hits'] += 1
                                        return subset
                                else:
                                    subset = cached_data.loc[:, cached_data.columns.get_level_values(1).isin(found)]
                                    if not subset.empty:
                                        self._batch_cache[batch_key] = subset
                                        self._stats['av_cache_hits'] += 1
                                        return subset
                        else:
                            if len(ticker_list) == 1:
                                self._stats['av_cache_hits'] += 1
                                return cached_data
                    except Exception:
                        pass

        # å•ç‹¬tickerç›´æ¥ç¼“å­˜æŸ¥æ‰¾
        if len(ticker_list) == 1:
            single_key = f"{ticker_list[0]}|single"
            if single_key in self._batch_cache:
                self._stats['av_cache_hits'] += 1
                return self._batch_cache[single_key]

        # â•â•â•â• Alpha Vantage è·å–ï¼ˆä¸»æ•°æ®æºï¼‰â•â•â•â•
        # æ ¹æ®periodè®¡ç®—éœ€è¦å¤šå°‘å¤©æ•°æ®
        period_days = self._period_to_days(period)
        all_dfs = {}
        av_failed_tickers = []

        for ticker in ticker_list:
            # æ£€æŸ¥å•tickerç¼“å­˜ï¼ˆpreloadæˆ–ä¹‹å‰çš„è¯·æ±‚å¯èƒ½å·²ç¼“å­˜ï¼‰
            single_key = f"{ticker}|single"
            if single_key in self._batch_cache:
                df = self._batch_cache[single_key]
                if df is not None and len(df) > 0:
                    all_dfs[ticker] = df
                    self._stats['av_cache_hits'] += 1
                    continue

            # è·³è¿‡æ— æ³•é€šè¿‡AVè·å–çš„ticker
            if ticker in INDEX_TO_ETF and INDEX_TO_ETF[ticker] is None:
                av_failed_tickers.append(ticker)
                continue

            # AVå·²é™æµæ—¶ï¼Œç›´æ¥è·³åˆ°yfinanceé™çº§
            if self._av_rate_limited:
                av_failed_tickers.append(ticker)
                continue

            df = self._fetch_single_ticker_av(ticker)
            if df is not None and not df.empty:
                # æŒ‰periodæˆªå–
                if period_days > 0 and len(df) > period_days:
                    df = df.iloc[-period_days:]
                all_dfs[ticker] = df
                self._batch_cache[single_key] = df
            else:
                av_failed_tickers.append(ticker)

        # AVå¤±è´¥çš„tickerå°è¯•yfinanceé™çº§ï¼ˆé™æµæ—¶æ‰¹é‡é™çº§æ›´é«˜æ•ˆï¼‰
        still_failed = list(av_failed_tickers)
        if av_failed_tickers:
            yf_result = self._yfinance_fallback(av_failed_tickers, period, interval)
            if yf_result is not None:
                for t in av_failed_tickers:
                    yf_closes = self.get_closes(yf_result, t)
                    if yf_closes is not None:
                        # ä»yfinanceç»“æœä¸­æå–å•tickerçš„DF
                        try:
                            if isinstance(yf_result.columns, pd.MultiIndex):
                                if t in yf_result.columns.get_level_values(1):
                                    single_df = yf_result.xs(t, level=1, axis=1)
                                    all_dfs[t] = single_df
                                    self._batch_cache[f"{t}|single"] = single_df
                                    still_failed.remove(t) if t in still_failed else None
                            else:
                                all_dfs[t] = yf_result
                                self._batch_cache[f"{t}|single"] = yf_result
                                still_failed.remove(t) if t in still_failed else None
                        except Exception:
                            pass

        # ç¬¬ä¸‰å±‚é™çº§ï¼šAkShareç¾è‚¡æ•°æ®ï¼ˆå½“AVå’Œyfinanceéƒ½å¤±è´¥æ—¶ï¼‰
        if still_failed:
            ak_results = self._akshare_us_fallback(still_failed, period)
            for t, df in ak_results.items():
                if df is not None and not df.empty:
                    all_dfs[t] = df
                    self._batch_cache[f"{t}|single"] = df

        if not all_dfs:
            return None

        # ç»„è£…ç»“æœ
        if len(all_dfs) == 1:
            ticker = list(all_dfs.keys())[0]
            result = all_dfs[ticker]
        else:
            # å¤šticker â†’ MultiIndex DataFrameï¼ˆä¸yfinanceæ ¼å¼å…¼å®¹ï¼‰
            result = self._merge_to_multiindex(all_dfs)

        if result is not None and not result.empty:
            self._batch_cache[batch_key] = result
        return result

    def _merge_to_multiindex(self, dfs: Dict[str, Any]) -> Any:
        """å°†å¤šä¸ªå•ticker DataFrameåˆå¹¶ä¸ºMultiIndexæ ¼å¼ï¼ˆå…¼å®¹yfinanceï¼‰"""
        import pandas as pd

        if not dfs:
            return None

        panels = {}
        for ticker, df in dfs.items():
            for col in ['Open', 'High', 'Low', 'Close', 'Volume']:
                if col in df.columns:
                    if col not in panels:
                        panels[col] = {}
                    panels[col][ticker] = df[col]

        if not panels:
            return None

        # æ„å»ºMultiIndex
        combined_dfs = []
        for col, ticker_series in panels.items():
            panel_df = pd.DataFrame(ticker_series)
            panel_df.columns = pd.MultiIndex.from_product([[col], panel_df.columns])
            combined_dfs.append(panel_df)

        if combined_dfs:
            result = pd.concat(combined_dfs, axis=1)
            result.sort_index(inplace=True)
            return result
        return None

    def _period_to_days(self, period: str) -> int:
        """å°†yfinanceé£æ ¼çš„periodè½¬ä¸ºå¤©æ•°"""
        period = period.lower().strip()
        if period.endswith('d'):
            return int(period[:-1])
        elif period.endswith('mo'):
            return int(period[:-2]) * 22  # äº¤æ˜“æ—¥
        elif period.endswith('y'):
            return int(period[:-1]) * 252
        return 66  # é»˜è®¤3ä¸ªæœˆ

    def _yfinance_fallback(self, tickers: list, period: str, interval: str) -> Any:
        """yfinanceé™çº§è·å–æ•°æ®ï¼ˆå«å¯ç”¨æ€§çŸ­è·¯ï¼‰"""
        # å·²æ¢æµ‹åˆ°yfinanceä¸å¯ç”¨æ—¶ç›´æ¥è·³è¿‡
        if self._yf_available is False:
            return None
        try:
            import yfinance as yf
            ticker_str = ' '.join(tickers)
            self._rate_limit('yfinance', YFINANCE_BATCH_DELAY)

            data = yf.download(tickers=ticker_str, period=period, interval=interval,
                               progress=False, threads=True, timeout=10)
            if data is not None and not data.empty:
                self._stats['yf_downloads'] += 1
                if self._yf_available is None:
                    self._yf_available = True
                return data
            else:
                # è¿”å›ç©ºç»“æœä¹Ÿè§†ä¸ºä¸å¯ç”¨
                if self._yf_available is None:
                    self._yf_available = False
                return None
        except Exception as e:
            print(f"    âš ï¸ yfinanceé™çº§å¤±è´¥: {str(e)[:60]}")
            self._stats['errors'] += 1
            if self._yf_available is None:
                self._yf_available = False
        return None

    # â”€â”€â”€ AkShare ç¾è‚¡é™çº§å±‚ï¼ˆç¬¬ä¸‰å±‚é™çº§ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _akshare_us_fallback(self, tickers: list, period: str = "3mo") -> Dict[str, Any]:
        """AkShareè·å–ç¾è‚¡å†å²ä»·æ ¼æ•°æ®ï¼ˆå½“AVå’Œyfinanceéƒ½å¤±è´¥æ—¶çš„ç¬¬ä¸‰å±‚é™çº§ï¼‰
        è¿”å›: {ticker: DataFrame} å­—å…¸ï¼ŒDataFrameåŒ…å« Open/High/Low/Close/Volume åˆ—
        """
        import pandas as pd
        results = {}
        period_days = self._period_to_days(period)
        if period_days <= 0:
            period_days = 90  # é»˜è®¤3ä¸ªæœˆ

        for ticker in tickers:
            # æŒ‡æ•°ticker â†’ é€šè¿‡ETFä»£ç†è·å–ï¼ˆç”¨åŸå§‹æŒ‡æ•°tickerä½œä¸ºkeyå­˜å‚¨ï¼‰
            if ticker.startswith('^'):
                etf = INDEX_TO_ETF.get(ticker)
                if not etf:
                    continue
                etf_code = self._get_akshare_us_code(etf)
                if not etf_code:
                    continue
                try:
                    import akshare as ak
                    self._rate_limit('akshare_us', 0.3)
                    df = ak.stock_us_hist(symbol=etf_code, period="daily", adjust="qfq")
                    if df is not None and len(df) > 0:
                        col_map = {'æ—¥æœŸ': 'Date', 'å¼€ç›˜': 'Open', 'æ”¶ç›˜': 'Close',
                                   'æœ€é«˜': 'High', 'æœ€ä½': 'Low', 'æˆäº¤é‡': 'Volume'}
                        df = df.rename(columns=col_map)
                        df['Date'] = pd.to_datetime(df['Date'])
                        df = df.set_index('Date').sort_index()
                        keep_cols = [c for c in ['Open', 'High', 'Low', 'Close', 'Volume'] if c in df.columns]
                        df = df[keep_cols]
                        if period_days > 0 and len(df) > period_days:
                            df = df.iloc[-period_days:]
                        results[ticker] = df  # ç”¨åŸå§‹æŒ‡æ•°tickerä½œä¸ºkey
                        self._stats['akshare_calls'] += 1
                except Exception:
                    pass
                continue
            # åŠ å¯†è´§å¸ç”¨CoinGeckoé™çº§
            if ticker in CRYPTO_MAP or ticker in FX_MAP:
                crypto_df = self._coingecko_fallback(ticker, period_days)
                if crypto_df is not None:
                    results[ticker] = crypto_df
                continue

            ak_code = self._get_akshare_us_code(ticker)
            if not ak_code:
                continue

            try:
                import akshare as ak
                self._rate_limit('akshare_us', 0.3)
                df = ak.stock_us_hist(symbol=ak_code, period="daily", adjust="qfq")
                if df is not None and len(df) > 0:
                    # è½¬æ¢åˆ—åä¸ºè‹±æ–‡æ ‡å‡†æ ¼å¼
                    col_map = {'æ—¥æœŸ': 'Date', 'å¼€ç›˜': 'Open', 'æ”¶ç›˜': 'Close',
                               'æœ€é«˜': 'High', 'æœ€ä½': 'Low', 'æˆäº¤é‡': 'Volume'}
                    df = df.rename(columns=col_map)
                    df['Date'] = pd.to_datetime(df['Date'])
                    df = df.set_index('Date').sort_index()
                    # åªä¿ç•™éœ€è¦çš„åˆ—
                    keep_cols = [c for c in ['Open', 'High', 'Low', 'Close', 'Volume'] if c in df.columns]
                    df = df[keep_cols]
                    # æŒ‰periodæˆªå–
                    if period_days > 0 and len(df) > period_days:
                        df = df.iloc[-period_days:]
                    results[ticker] = df
                    self._stats['akshare_calls'] += 1
            except Exception as e:
                # è®°å½•å¤±è´¥åŸå› å¸®åŠ©è¯Šæ–­
                if hasattr(self, '_akshare_failures'):
                    self._akshare_failures[ticker] = str(e)[:60]

        return results

    def _get_akshare_us_code(self, ticker: str) -> str:
        """å°†æ ‡å‡†tickerè½¬æ¢ä¸ºAkShareä¸œæ–¹è´¢å¯Œç¾è‚¡ä»£ç """
        # å…ˆæŸ¥é™æ€æ˜ å°„
        if ticker in AKSHARE_US_PREFIX:
            return AKSHARE_US_PREFIX[ticker]

        # åŠ¨æ€å°è¯•ï¼šä¾æ¬¡å°è¯• 106(æ­£è‚¡) / 105(NASDAQ) / 107(NYSE ETF) å‰ç¼€
        for prefix in ['106', '105', '107']:
            code = f"{prefix}.{ticker}"
            try:
                import akshare as ak
                df = ak.stock_us_hist(symbol=code, period="daily", adjust="qfq")
                if df is not None and len(df) > 0:
                    AKSHARE_US_PREFIX[ticker] = code  # ç¼“å­˜æ˜ å°„
                    return code
            except Exception:
                continue
        return ''

    def _akshare_batch_preload(self, tickers: list, period: str = "3mo"):
        """AkShareæ‰¹é‡é¢„åŠ è½½ç¾è‚¡ä»·æ ¼æ•°æ®åˆ°ç¼“å­˜"""
        results = self._akshare_us_fallback(tickers, period)
        loaded = 0
        for ticker, df in results.items():
            if df is not None and not df.empty:
                self._batch_cache[f"{ticker}|single"] = df
                loaded += 1
        if loaded > 0:
            print(f"    âœ… AkShareç¾è‚¡é™çº§åŠ è½½: {loaded}/{len(tickers)}ä¸ªticker")
        return loaded

    # â”€â”€â”€ CoinGecko åŠ å¯†è´§å¸é™çº§å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # CoinGecko IDæ˜ å°„
    COINGECKO_MAP = {
        'BTC-USD': 'bitcoin',
        'ETH-USD': 'ethereum',
        'SOL-USD': 'solana',
        'BNB-USD': 'binancecoin',
        'ADA-USD': 'cardano',
        'DOGE-USD': 'dogecoin',
        'XRP-USD': 'ripple',
        'AVAX-USD': 'avalanche-2',
    }

    # æ³•å¸æ±‡ç‡æ˜ å°„ï¼ˆCoinGeckoæ”¯æŒæ³•å¸å¯¹USDï¼‰
    FX_COINGECKO_MAP = {
        'CNY=X': ('usd', 'cny'),  # USD/CNY
    }

    def _coingecko_fallback(self, ticker: str, period_days: int = 90) -> Any:
        """CoinGeckoé™çº§è·å–åŠ å¯†è´§å¸/æ±‡ç‡ä»·æ ¼æ•°æ®
        è¿”å›æ ‡å‡†DataFrameï¼ˆOpen/High/Low/Close/Volumeåˆ—ï¼‰
        """
        import pandas as pd

        # åŠ å¯†è´§å¸
        coin_id = self.COINGECKO_MAP.get(ticker)
        if coin_id:
            return self._coingecko_fetch_coin(coin_id, ticker, period_days)

        # æ±‡ç‡ï¼ˆCNY=Xç­‰ï¼‰
        if ticker in self.FX_COINGECKO_MAP:
            return self._coingecko_fetch_fx(ticker, period_days)

        # ä¹Ÿæ£€æŸ¥å…¨å±€CRYPTO_MAPï¼ˆå…¼å®¹ï¼‰
        if ticker in CRYPTO_MAP:
            coin_id = ticker.replace('-USD', '').lower()
            # å¸¸è§ç®€å†™æ˜ å°„
            simple_map = {'btc': 'bitcoin', 'eth': 'ethereum', 'sol': 'solana'}
            coin_id = simple_map.get(coin_id, coin_id)
            return self._coingecko_fetch_coin(coin_id, ticker, period_days)

        return None

    def _coingecko_fetch_coin(self, coin_id: str, ticker: str, period_days: int) -> Any:
        """ä»CoinGeckoè·å–åŠ å¯†è´§å¸å†å²ä»·æ ¼"""
        import pandas as pd

        try:
            self._rate_limit('coingecko', 1.5)  # CoinGeckoå…è´¹ç‰ˆé™æµï¼š10-30æ¬¡/åˆ†é’Ÿ
            url = f"https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart"
            params = {'vs_currency': 'usd', 'days': str(period_days), 'interval': 'daily'}
            resp = self._session.get(url, params=params, timeout=15)

            if resp.status_code == 429:
                print(f"      âš ï¸ CoinGeckoé™æµï¼Œè·³è¿‡{ticker}")
                return None
            if resp.status_code != 200:
                return None

            data = resp.json()
            prices = data.get('prices', [])
            volumes = data.get('total_volumes', [])

            if not prices or len(prices) < 2:
                return None

            # æ„å»ºDataFrame
            rows = []
            vol_dict = {int(v[0]): v[1] for v in volumes} if volumes else {}

            for i, (ts_ms, price) in enumerate(prices):
                dt = pd.Timestamp(ts_ms, unit='ms').normalize()
                vol = vol_dict.get(int(ts_ms), 0)

                # CoinGeckoåªæä¾›æ”¶ç›˜ä»·ï¼Œç”¨ç›¸é‚»ä»·æ ¼ä¼°ç®—OHLC
                if i > 0:
                    prev_price = prices[i-1][1]
                    open_price = prev_price
                    high_price = max(price, prev_price)
                    low_price = min(price, prev_price)
                else:
                    open_price = price
                    high_price = price
                    low_price = price

                rows.append({
                    'Date': dt,
                    'Open': float(open_price),
                    'High': float(high_price),
                    'Low': float(low_price),
                    'Close': float(price),
                    'Volume': float(vol),
                })

            df = pd.DataFrame(rows)
            # å»é‡æ—¥æœŸï¼ˆCoinGeckoæœ‰æ—¶è¿”å›åŒä¸€å¤©å¤šä¸ªæ•°æ®ç‚¹ï¼‰
            df = df.drop_duplicates(subset='Date', keep='last')
            df = df.set_index('Date').sort_index()

            if not df.empty:
                self._stats['akshare_calls'] += 1  # å¤ç”¨ç»Ÿè®¡å­—æ®µ
                print(f"      âœ… CoinGecko {ticker}: {len(df)}å¤©æ•°æ®, æœ€æ–°${float(df['Close'].iloc[-1]):,.0f}")
            return df

        except Exception as e:
            print(f"      âš ï¸ CoinGecko {ticker} å¤±è´¥: {str(e)[:60]}")
            return None

    def _coingecko_fetch_fx(self, ticker: str, period_days: int) -> Any:
        """ä»CoinGeckoè·å–æ³•å¸æ±‡ç‡ï¼ˆé€šè¿‡BTCä»·æ ¼é—´æ¥è®¡ç®—ï¼‰
        åŸç†ï¼šUSD/CNY = BTCä»·æ ¼(CNY) / BTCä»·æ ¼(USD)
        """
        import pandas as pd

        base_cur, quote_cur = self.FX_COINGECKO_MAP[ticker]

        try:
            self._rate_limit('coingecko', 1.5)
            # ç”¨ç¨³å®šå¸USDTåšä»£ç†è·å–æ±‡ç‡
            url = "https://api.coingecko.com/api/v3/coins/tether/market_chart"
            params = {'vs_currency': quote_cur.lower(), 'days': str(min(period_days, 365)), 'interval': 'daily'}
            resp = self._session.get(url, params=params, timeout=15)

            if resp.status_code != 200:
                return None

            data = resp.json()
            prices = data.get('prices', [])
            if not prices or len(prices) < 2:
                return None

            rows = []
            for ts_ms, price in prices:
                dt = pd.Timestamp(ts_ms, unit='ms').normalize()
                rows.append({
                    'Date': dt,
                    'Open': float(price),
                    'High': float(price),
                    'Low': float(price),
                    'Close': float(price),
                    'Volume': 0,
                })

            df = pd.DataFrame(rows)
            df = df.drop_duplicates(subset='Date', keep='last')
            df = df.set_index('Date').sort_index()

            if not df.empty:
                print(f"      âœ… CoinGecko {ticker}: {len(df)}å¤©æ±‡ç‡æ•°æ®")
            return df

        except Exception as e:
            print(f"      âš ï¸ CoinGecko {ticker} æ±‡ç‡å¤±è´¥: {str(e)[:60]}")
            return None

    # â”€â”€â”€ Ticker Infoï¼ˆå…¬å¸åŸºæœ¬é¢ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def get_ticker_info(self, ticker: str, max_retries: int = 3) -> dict:
        """è·å–å•åªè‚¡ç¥¨è¯¦ç»†ä¿¡æ¯ï¼ˆAlpha Vantage OVERVIEW + GLOBAL_QUOTEï¼‰"""
        if ticker in self._info_cache:
            self._stats['av_cache_hits'] += 1
            return self._info_cache[ticker]

        info = {}

        # Alpha Vantage OVERVIEW
        overview = self._av_get_overview(ticker)
        if overview and 'Symbol' in overview:
            info = {
                'shortName': overview.get('Name', ticker),
                'symbol': overview.get('Symbol', ticker),
                'sector': overview.get('Sector', ''),
                'industry': overview.get('Industry', ''),
                'marketCap': self._safe_float(overview.get('MarketCapitalization', 0)),
                'currentPrice': 0,  # åé¢ç”¨GLOBAL_QUOTEè¡¥å……
                'forwardPE': self._safe_float(overview.get('ForwardPE', 0)),
                'trailingPE': self._safe_float(overview.get('PERatio', 0)),
                'pegRatio': self._safe_float(overview.get('PEGRatio', 0)),
                'returnOnEquity': self._safe_float(overview.get('ReturnOnEquityTTM', 0)),
                'profitMargins': self._safe_float(overview.get('ProfitMargin', 0)),
                'operatingMargins': self._safe_float(overview.get('OperatingMarginTTM', 0)),
                'debtToEquity': self._safe_float(overview.get('DebtToEquity', 0)) if overview.get('DebtToEquity') else 0,
                'freeCashflow': 0,  # AV OVERVIEW æ²¡æœ‰ç›´æ¥æä¾›
                'netIncomeToCommon': self._safe_float(overview.get('NetIncomeTTM', 0)) if overview.get('NetIncomeTTM') else 0,
                'beta': self._safe_float(overview.get('Beta', 0)),
                'dividendYield': self._safe_float(overview.get('DividendYield', 0)),
                'regularMarketPreviousClose': self._safe_float(overview.get('PreviousClose', 0)) if overview.get('PreviousClose') else 0,
                'heldPercentInstitutions': 0,  # AVæ²¡æœ‰
                '_source': 'alpha_vantage',
            }

        # Alpha Vantage GLOBAL_QUOTEï¼ˆè·å–æœ€æ–°ä»·æ ¼ï¼‰
        quote = self._av_get_global_quote(ticker)
        if quote and 'Global Quote' in quote and quote['Global Quote']:
            gq = quote['Global Quote']
            price = self._safe_float(gq.get('05. price', 0))
            prev_close = self._safe_float(gq.get('08. previous close', 0))
            change_pct_str = gq.get('10. change percent', '0%').replace('%', '')
            change_pct = self._safe_float(change_pct_str)

            if info:
                info['currentPrice'] = price
                info['regularMarketPrice'] = price
                info['regularMarketPreviousClose'] = prev_close or info.get('regularMarketPreviousClose', 0)
                info['_change_pct'] = change_pct
            else:
                # åªæœ‰GLOBAL_QUOTEæˆåŠŸ
                info = {
                    'shortName': ticker,
                    'symbol': ticker,
                    'currentPrice': price,
                    'regularMarketPrice': price,
                    'regularMarketPreviousClose': prev_close,
                    '_change_pct': change_pct,
                    '_source': 'alpha_vantage_quote_only',
                }

        if info and len(info) > 3:
            self._info_cache[ticker] = info
            return info

        # ä»ç¼“å­˜ä»·æ ¼æ•°æ®æ„å»ºæœ€åŸºæœ¬infoï¼ˆAVé™æµé™çº§ç­–ç•¥ï¼‰
        cache_info = self._build_info_from_cache(ticker)
        if cache_info:
            return cache_info

        # é™çº§yfinance
        yf_info = self._yfinance_get_info_fallback(ticker)
        if yf_info:
            return yf_info

        # ç¬¬ä¸‰å±‚ï¼šAkShareè·å–ä»·æ ¼åæ„å»ºinfo
        ak_results = self._akshare_us_fallback([ticker], "3mo")
        if ticker in ak_results and ak_results[ticker] is not None:
            self._batch_cache[f"{ticker}|single"] = ak_results[ticker]
            return self._build_info_from_cache(ticker)

        return {}

    # å¸¸è§ticker â†’ å…¬å¸åæ˜ å°„ï¼ˆç”¨äºç¼“å­˜é™çº§æ—¶æä¾›å¯è¯»åç§°ï¼‰
    TICKER_NAMES = {
        'AAPL': 'è‹¹æœ', 'MSFT': 'å¾®è½¯', 'GOOGL': 'è°·æ­Œ', 'NVDA': 'è‹±ä¼Ÿè¾¾',
        'META': 'Meta', 'AMZN': 'äºšé©¬é€Š', 'TSLA': 'ç‰¹æ–¯æ‹‰', 'AVGO': 'åšé€š',
        'TSM': 'å°ç§¯ç”µ', 'AMD': 'AMD', 'LLY': 'ç¤¼æ¥', 'JPM': 'æ‘©æ ¹å¤§é€š',
        'BRK-B': 'ä¼¯å…‹å¸Œå°”', 'V': 'Visa', 'UNH': 'è”åˆå¥åº·', 'NFLX': 'å¥ˆé£',
        'CRM': 'Salesforce', 'COST': 'Costco', 'XOM': 'åŸƒå…‹æ£®ç¾å­š',
        'NVO': 'è¯ºå’Œè¯ºå¾·', 'TCEHY': 'è…¾è®¯ADR', 'BABA': 'é˜¿é‡Œå·´å·´', 'PDD': 'æ‹¼å¤šå¤š',
    }

    # å·²çŸ¥ä»·æ ¼åˆç†èŒƒå›´ï¼ˆç”¨äºå¼‚å¸¸æ£€æµ‹ï¼ŒåŸºäº2025-2026å¹´å¸‚ä»·åŒºé—´ï¼‰
    PRICE_SANITY = {
        'AAPL': (120, 400), 'MSFT': (250, 700), 'GOOGL': (100, 400), 'NVDA': (50, 300),
        'META': (300, 900), 'AMZN': (120, 350), 'TSLA': (100, 600), 'AVGO': (80, 500),
        'TSM': (100, 500), 'AMD': (60, 300), 'LLY': (400, 1500), 'JPM': (120, 400),
        'V': (180, 450), 'UNH': (200, 750), 'NFLX': (400, 1500), 'CRM': (120, 500),
        'COST': (500, 1500), 'XOM': (60, 200), 'NVO': (30, 250),
        'TCEHY': (25, 100), 'BABA': (40, 250), 'PDD': (50, 250), 'BRK-B': (300, 700),
    }

    def _build_info_from_cache(self, ticker: str) -> dict:
        """ä»å·²ç¼“å­˜çš„ä»·æ ¼æ•°æ®æ„å»ºåŸºæœ¬ticker infoï¼ˆAVé™æµæ—¶é™çº§ç”¨ï¼‰"""
        single_key = f"{ticker}|single"
        df = self._batch_cache.get(single_key)
        if df is None or df.empty:
            return {}

        try:
            if 'Close' not in df.columns:
                return {}
            closes = df['Close'].dropna()
            if len(closes) < 2:
                return {}

            price = float(closes.iloc[-1])
            prev_close = float(closes.iloc[-2])

            # æ•°æ®å¼‚å¸¸æ£€æµ‹ï¼šä»·æ ¼åˆç†æ€§æ ¡éªŒ
            if ticker in self.PRICE_SANITY:
                lo, hi = self.PRICE_SANITY[ticker]
                if price < lo * 0.5 or price > hi * 2:
                    # ä»·æ ¼ä¸¥é‡å¼‚å¸¸ï¼Œå°è¯•ç”¨5æ—¥å‡ä»·ä¿®æ­£
                    recent = closes.iloc[-5:] if len(closes) >= 5 else closes
                    median_price = float(recent.median())
                    if lo * 0.5 <= median_price <= hi * 2:
                        price = median_price
                        prev_close = float(closes.iloc[-6]) if len(closes) >= 6 else float(closes.iloc[-2])

            change_pct = ((price - prev_close) / prev_close * 100) if prev_close > 0 else 0

            name = self.TICKER_NAMES.get(ticker, ticker)
            info = {
                'shortName': name,
                'symbol': ticker,
                'currentPrice': price,
                'regularMarketPrice': price,
                'regularMarketPreviousClose': prev_close,
                '_change_pct': change_pct,
                '_source': 'cache_fallback',
            }
            self._info_cache[ticker] = info
            return info
        except Exception:
            return {}

    def _yfinance_get_info_fallback(self, ticker: str) -> dict:
        """yfinanceé™çº§è·å–ticker infoï¼ˆå«å¯ç”¨æ€§çŸ­è·¯ï¼‰"""
        if self._yf_available is False:
            return {}
        try:
            import yfinance as yf
            self._rate_limit('yfinance_info', YFINANCE_TICKER_INFO_DELAY)
            t = yf.Ticker(ticker=ticker)
            info = t.info
            if info and len(info) > 5:
                self._info_cache[ticker] = info
                if self._yf_available is None:
                    self._yf_available = True
                return info
        except Exception as e:
            if self._yf_available is None:
                self._yf_available = False
        return {}

    def _fetch_stockanalysis_fundamentals(self, ticker: str) -> dict:
        """ä»stockanalysis.comç½‘é¡µæŠ“å–åŸºæœ¬é¢æ•°æ®ï¼ˆROE/PE/è´Ÿå€ºç‡ç­‰ï¼‰
        ä½œä¸ºAVå’Œyfinanceéƒ½å¤±è´¥æ—¶çš„æœ€ç»ˆé™çº§å±‚"""
        import urllib.request
        import re
        import ssl

        # BRK-B åœ¨ stockanalysis ä¸Šç”¨ brk.b
        url_ticker = ticker.lower().replace('-', '.')
        url = f"https://stockanalysis.com/stocks/{url_ticker}/financials/ratios/"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Accept-Language': 'en-US,en;q=0.9',
        }
        ctx = ssl.create_default_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE

        try:
            self._rate_limit('stockanalysis', 1.5)
            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=15, context=ctx) as resp:
                html = resp.read().decode('utf-8', errors='ignore')

            result = {}

            # è§£æ ROE â€” æŸ¥æ‰¾ "Return on Equity (ROE)" åçš„ç™¾åˆ†æ¯”æ•°å€¼
            m = re.search(r'Return on Equity.*?([0-9.-]+)%', html, re.DOTALL)
            if m:
                result['returnOnEquity'] = float(m.group(1)) / 100

            # è§£æ PE Ratio
            m = re.search(r'PE Ratio.*?([0-9.,]+)', html, re.DOTALL)
            if m:
                result['forwardPE'] = float(m.group(1).replace(',', ''))

            # è§£æ Debt/Equity
            m = re.search(r'Debt / Equity.*?([0-9.,]+)', html, re.DOTALL)
            if m:
                result['debtToEquity'] = float(m.group(1).replace(',', '')) * 100

            # è§£æ Profit Margin (å‡€åˆ©æ¶¦ç‡)
            # å¯èƒ½åœ¨ ratios é¡µé¢æ²¡æœ‰ï¼Œä½† ROE/PE/Debt å·²ç»è¶³å¤Ÿ
            if result.get('returnOnEquity') or result.get('forwardPE'):
                result['_source'] = 'stockanalysis_web'
                print(f"      ğŸŒ {ticker}: ROE={result.get('returnOnEquity', 'N/A')} PE={result.get('forwardPE', 'N/A')} D/E={result.get('debtToEquity', 'N/A')}")
                return result

        except Exception as e:
            pass

        return {}

    def _enrich_cache_fallback_with_fundamentals(self, results: Dict[str, dict]) -> Dict[str, dict]:
        """å¯¹ç¼“å­˜é™çº§(ä»…æœ‰ä»·æ ¼)çš„ç»“æœï¼Œå°è¯•ä»stockanalysis.comè¡¥å……åŸºæœ¬é¢æ•°æ®"""
        need_enrich = [
            ticker for ticker, info in results.items()
            if info.get('_source') in ('cache_fallback', 'alpha_vantage_quote_only')
            and not info.get('returnOnEquity')
            and not info.get('forwardPE')
        ]
        if not need_enrich:
            return results

        print(f"    ğŸŒ å°è¯•ä»stockanalysis.comè¡¥å……{len(need_enrich)}åªè‚¡ç¥¨åŸºæœ¬é¢...")
        enriched = 0
        for ticker in need_enrich:
            fundamentals = self._fetch_stockanalysis_fundamentals(ticker)
            if fundamentals:
                info = results[ticker]
                info['returnOnEquity'] = fundamentals.get('returnOnEquity', 0)
                info['forwardPE'] = fundamentals.get('forwardPE', 0)
                info['debtToEquity'] = fundamentals.get('debtToEquity', 0)
                info['profitMargins'] = fundamentals.get('profitMargins', 0)
                info['_source'] = 'cache_plus_stockanalysis'
                results[ticker] = info
                self._info_cache[ticker] = info
                enriched += 1
        if enriched:
            print(f"    âœ… æˆåŠŸè¡¥å……{enriched}/{len(need_enrich)}åªè‚¡ç¥¨åŸºæœ¬é¢æ•°æ®")
        return results

    def batch_get_ticker_info(self, tickers: List[str], batch_size: int = 5) -> Dict[str, dict]:
        """åˆ†æ‰¹è·å–å¤šåªè‚¡ç¥¨ä¿¡æ¯ï¼ˆAVä¼˜å…ˆ â†’ ç¼“å­˜é™çº§ â†’ yfinanceé™çº§ï¼‰"""
        results = {}
        uncached = [t for t in tickers if t not in self._info_cache]
        cached = {t: self._info_cache[t] for t in tickers if t in self._info_cache}
        results.update(cached)

        if cached:
            self._stats['av_cache_hits'] += len(cached)

        # AVå…¨å±€é™æµæ—¶ï¼Œå…ˆå°è¯•yfinance/AkShareæ‰¹é‡ä¸‹è½½ä»·æ ¼æ•°æ®å¡«å……ç¼“å­˜
        if self._av_rate_limited and uncached:
            print(f"      âš ï¸ AVé™æµä¸­ï¼Œå°è¯•æ‰¹é‡è·å–{len(uncached)}åªè‚¡ç¥¨ä»·æ ¼...")
            self._preload_stock_prices_yf(uncached)
            # yfinanceä¹‹åä»æœªç¼“å­˜çš„ï¼Œèµ°AkShare
            still_need = [t for t in uncached if f"{t}|single" not in self._batch_cache]
            if still_need:
                self._akshare_batch_preload(still_need)

        for i in range(0, len(uncached), batch_size):
            batch = uncached[i:i + batch_size]
            for ticker in batch:
                info = self.get_ticker_info(ticker)
                if info:
                    results[ticker] = info
            if batch:
                print(f"      ğŸ“Š Infoæ‰¹æ¬¡ {i//batch_size + 1}: {len(batch)}åªå®Œæˆ")

        # æœ€ç»ˆé™çº§å±‚ï¼šå¯¹ä»…æœ‰ä»·æ ¼çš„è‚¡ç¥¨ï¼Œä»stockanalysis.comè¡¥å……åŸºæœ¬é¢
        results = self._enrich_cache_fallback_with_fundamentals(results)

        return results

    def _preload_stock_prices_yf(self, tickers: List[str]):
        """ç”¨yfinanceæ‰¹é‡é¢„åŠ è½½è‚¡ç¥¨ä»·æ ¼æ•°æ®ï¼ˆä¾›ç¼“å­˜é™çº§ä½¿ç”¨ï¼‰
        å¦‚æœyfinanceä¸å¯ç”¨ï¼ˆè¶…æ—¶/é™æµï¼‰ï¼Œå¿«é€Ÿæ”¾å¼ƒè®©AkShareæ¥ç®¡"""
        # è¿‡æ»¤æ‰å·²ç¼“å­˜çš„ticker
        need_load = [t for t in tickers if f"{t}|single" not in self._batch_cache]
        if not need_load:
            return

        # å…ˆç”¨ä¸€å°æ‰¹æµ‹è¯•yfinanceå¯ç”¨æ€§ï¼ˆé¿å…æ‰€æœ‰tickeréƒ½è¶…æ—¶æµªè´¹æ—¶é—´ï¼‰
        test_batch = need_load[:3]
        yf_data = self._yfinance_fallback(test_batch, "3mo", "1d")
        if yf_data is None:
            print(f"      âš ï¸ yfinanceä¸å¯ç”¨ï¼Œè·³è¿‡ï¼ˆå°†ç”±AkShareæ¥ç®¡ï¼‰")
            return

        # yfinanceå¯ç”¨ï¼Œç»§ç»­ä¸‹è½½å‰©ä½™
        import pandas as pd
        loaded = 0
        for t in test_batch:
            try:
                if isinstance(yf_data.columns, pd.MultiIndex):
                    if t in yf_data.columns.get_level_values(1):
                        single_df = yf_data.xs(t, level=1, axis=1)
                        self._batch_cache[f"{t}|single"] = single_df
                        loaded += 1
                else:
                    if len(test_batch) == 1:
                        self._batch_cache[f"{t}|single"] = yf_data
                        loaded += 1
            except Exception:
                pass

        remaining = [t for t in need_load[3:] if f"{t}|single" not in self._batch_cache]
        batch_size = 20
        for i in range(0, len(remaining), batch_size):
            batch = remaining[i:i + batch_size]
            yf_data = self._yfinance_fallback(batch, "3mo", "1d")
            if yf_data is not None:
                for t in batch:
                    try:
                        if isinstance(yf_data.columns, pd.MultiIndex):
                            if t in yf_data.columns.get_level_values(1):
                                single_df = yf_data.xs(t, level=1, axis=1)
                                self._batch_cache[f"{t}|single"] = single_df
                                loaded += 1
                        else:
                            if len(batch) == 1:
                                self._batch_cache[f"{t}|single"] = yf_data
                                loaded += 1
                    except Exception:
                        pass
        if loaded > 0:
            print(f"      ğŸ“Š yfinanceä»·æ ¼: {loaded}åªæˆåŠŸ")

    @staticmethod
    def _safe_float(val) -> float:
        """å®‰å…¨è½¬æ¢ä¸ºfloat"""
        if val is None or val == '' or val == 'None' or val == '-':
            return 0.0
        try:
            return float(val)
        except (ValueError, TypeError):
            return 0.0

    # â”€â”€â”€ æ•°æ®æå–è¾…åŠ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def get_closes(self, data, ticker: str):
        """ä»æ‰¹é‡ä¸‹è½½ç»“æœä¸­å®‰å…¨æå–æ”¶ç›˜ä»·æ•°ç»„"""
        import numpy as np
        try:
            if data is None or data.empty:
                return None
            if isinstance(data.columns, __import__('pandas').MultiIndex):
                if 'Close' in data.columns.get_level_values(0):
                    level1_vals = data['Close'].columns.tolist()
                    if ticker in level1_vals:
                        arr = data['Close'][ticker].dropna().values
                    elif len(level1_vals) == 1:
                        arr = data['Close'].iloc[:, 0].dropna().values
                    else:
                        # å°è¯•ETFä»£ç†
                        etf = INDEX_TO_ETF.get(ticker)
                        if etf and etf in level1_vals:
                            arr = data['Close'][etf].dropna().values
                        else:
                            return None
                else:
                    return None
            else:
                if 'Close' in data.columns:
                    arr = data['Close'].dropna().values
                else:
                    return None
            return arr if len(arr) > 0 else None
        except Exception:
            return None

    def get_volumes(self, data, ticker: str):
        """ä»æ‰¹é‡ä¸‹è½½ç»“æœä¸­å®‰å…¨æå–æˆäº¤é‡æ•°ç»„"""
        import numpy as np
        try:
            if data is None or data.empty:
                return None
            if isinstance(data.columns, __import__('pandas').MultiIndex):
                if 'Volume' in data.columns.get_level_values(0):
                    if ticker in data['Volume'].columns:
                        arr = data['Volume'][ticker].dropna().values
                        return arr if len(arr) > 0 else None
                    etf = INDEX_TO_ETF.get(ticker)
                    if etf and etf in data['Volume'].columns:
                        arr = data['Volume'][etf].dropna().values
                        return arr if len(arr) > 0 else None
            else:
                if 'Volume' in data.columns:
                    arr = data['Volume'].dropna().values
                    return arr if len(arr) > 0 else None
            return None
        except Exception:
            return None

    # â”€â”€â”€ é¢„åŠ è½½ï¼ˆä¸€æ¬¡æ€§æ‰¹é‡ä¸‹è½½ï¼Œè·¨Skillå…±äº«ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def preload_all(self, period: str = "3mo"):
        """
        é¢„åŠ è½½æ‰€æœ‰å¸¸ç”¨tickeræ•°æ®ï¼ˆAlpha Vantageä¼˜å…ˆï¼‰

        ç­–ç•¥:
        - å¯¹äºAVæ”¯æŒçš„tickeré€ä¸ªè·å–ï¼ˆå¸¦ç¼“å­˜ï¼‰
        - AVä¸æ”¯æŒçš„ï¼ˆå¦‚æŒ‡æ•°^VIX9Dç­‰ï¼‰èµ°yfinanceé™çº§
        - å­é›†ç¼“å­˜è®©åç»­Skillè¯·æ±‚ç›´æ¥ä»ç¼“å­˜æå–
        """
        print("  ğŸ“¡ é¢„åŠ è½½å…¨å±€å¸‚åœºæ•°æ®ï¼ˆAlpha Vantageä¼˜å…ˆï¼‰...")
        t0 = time.time()

        # æ”¶é›†æ‰€æœ‰éœ€è¦çš„tickerï¼ˆæŒ‰ç»„ä¼˜å…ˆçº§æ’åºï¼Œç¡®ä¿æ ¸å¿ƒtickerå…ˆåŠ è½½ï¼‰
        # ä¼˜å…ˆçº§ï¼šmarket_etf > indices > crypto > macro_bonds > china_etf > commodities > credit
        priority_order = ['market_etf', 'indices', 'crypto', 'macro_bonds', 'china_etf', 'commodities', 'credit']
        all_tickers_ordered = []
        seen = set()
        for group in priority_order:
            if group in self._preload_groups:
                for t in self._preload_groups[group].split():
                    if t not in seen:
                        all_tickers_ordered.append(t)
                        seen.add(t)

        # åˆ†ç±»ï¼ˆä¿æŒä¼˜å…ˆçº§é¡ºåºï¼‰
        av_tickers = []   # AVå¯è·å–
        yf_tickers = []   # éœ€è¦yfinance

        for t in all_tickers_ordered:
            if t in CRYPTO_MAP or t in FX_MAP:
                av_tickers.append(t)
            elif t in INDEX_TO_ETF:
                etf = INDEX_TO_ETF[t]
                if etf:
                    av_tickers.append(t)
                else:
                    yf_tickers.append(t)
            elif t.startswith('^'):
                yf_tickers.append(t)
            else:
                av_tickers.append(t)

        print(f"    AV: {len(av_tickers)}ä¸ªticker | yfinanceé™çº§: {len(yf_tickers)}ä¸ª")

        # AVæ‰¹é‡è·å–
        loaded = 0
        for i, ticker in enumerate(av_tickers):
            single_key = f"{ticker}|single"
            if single_key in self._batch_cache:
                loaded += 1
                continue

            # AVå·²é™æµï¼Œå°†å‰©ä½™tickerè½¬å…¥yfinanceé™çº§åˆ—è¡¨
            if self._av_rate_limited:
                yf_tickers.append(ticker)
                continue

            df = self._fetch_single_ticker_av(ticker)
            if df is not None and not df.empty:
                self._batch_cache[single_key] = df
                loaded += 1
            else:
                # AVè·å–å¤±è´¥ï¼ŒåŠ å…¥yfinanceé™çº§åˆ—è¡¨
                yf_tickers.append(ticker)
            if (i + 1) % 10 == 0:
                print(f"    ğŸ“¡ AVè¿›åº¦: {i+1}/{len(av_tickers)} ({loaded}æˆåŠŸ)")

        print(f"    âœ… AVåŠ è½½: {loaded}/{len(av_tickers)}ä¸ªticker"
              + (f" | {len(yf_tickers)}ä¸ªè½¬yfinanceé™çº§" if yf_tickers else ""))

        # yfinanceé™çº§è·å–ï¼ˆå…ˆç”¨å°æ‰¹æµ‹è¯•å¯ç”¨æ€§ï¼Œå¤±è´¥åˆ™è·³è¿‡å…¨éƒ¨ç”±AkShareæ¥ç®¡ï¼‰
        if yf_tickers:
            yf_tickers = list(set(yf_tickers))
            yf_loaded = 0

            # å…ˆæµ‹è¯•yfinanceå¯ç”¨æ€§ï¼ˆç”¨3ä¸ªtickeræ¢æµ‹ï¼‰
            test_batch = yf_tickers[:3]
            test_result = self._yfinance_fallback(test_batch, period, "1d")
            yf_available = test_result is not None and not test_result.empty

            if yf_available:
                import pandas as pd
                # å¤„ç†æµ‹è¯•æ‰¹ç»“æœ
                for t in test_batch:
                    try:
                        if isinstance(test_result.columns, pd.MultiIndex):
                            if t in test_result.columns.get_level_values(1):
                                single_df = test_result.xs(t, level=1, axis=1)
                                self._batch_cache[f"{t}|single"] = single_df
                                yf_loaded += 1
                        else:
                            if len(test_batch) == 1:
                                self._batch_cache[f"{t}|single"] = test_result
                                yf_loaded += 1
                    except Exception:
                        pass

                # ä¸‹è½½å‰©ä½™
                remaining = yf_tickers[3:]
                batch_size = 15
                for batch_start in range(0, len(remaining), batch_size):
                    batch = remaining[batch_start:batch_start + batch_size]
                    yf_data = self._yfinance_fallback(batch, period, "1d")
                    if yf_data is not None:
                        for t in batch:
                            try:
                                if isinstance(yf_data.columns, pd.MultiIndex):
                                    if t in yf_data.columns.get_level_values(1):
                                        single_df = yf_data.xs(t, level=1, axis=1)
                                        self._batch_cache[f"{t}|single"] = single_df
                                        yf_loaded += 1
                                else:
                                    if len(batch) == 1:
                                        self._batch_cache[f"{t}|single"] = yf_data
                                        yf_loaded += 1
                            except Exception:
                                pass
                print(f"    âœ… yfinanceé™çº§åŠ è½½: {yf_loaded}/{len(yf_tickers)}ä¸ªticker")
            else:
                print(f"    âš ï¸ yfinanceä¸å¯ç”¨ï¼ˆè¶…æ—¶/é™æµï¼‰ï¼Œè·³è¿‡{len(yf_tickers)}ä¸ªticker â†’ AkShareæ¥ç®¡")
            loaded += yf_loaded

        # ç¬¬ä¸‰å±‚é™çº§ï¼šAkShareç¾è‚¡ + CoinGeckoåŠ å¯†è´§å¸ï¼ˆå½“AVå’Œyfinanceéƒ½å¤±è´¥æ—¶ï¼‰
        still_missing = [t for t in all_tickers_ordered
                         if f"{t}|single" not in self._batch_cache
                         and not t.startswith('^')]
        if still_missing:
            # åˆ†ç¦»ï¼šç¾è‚¡èµ°AkShareï¼ŒåŠ å¯†è´§å¸/æ±‡ç‡èµ°CoinGecko
            ak_candidates = [t for t in still_missing if t not in CRYPTO_MAP and t not in FX_MAP]
            crypto_candidates = [t for t in still_missing if t in CRYPTO_MAP or t in FX_MAP]

            if ak_candidates:
                print(f"    ğŸ“¡ AkShareç¬¬ä¸‰å±‚é™çº§: å°è¯•è·å–{len(ak_candidates)}ä¸ªticker...")
                ak_loaded = self._akshare_batch_preload(ak_candidates, period)
                loaded += ak_loaded

            if crypto_candidates:
                print(f"    ğŸ“¡ CoinGeckoç¬¬ä¸‰å±‚é™çº§: å°è¯•è·å–{len(crypto_candidates)}ä¸ªåŠ å¯†/æ±‡ç‡ticker...")
                period_days = self._period_to_days(period)
                cg_loaded = 0
                for t in crypto_candidates:
                    df = self._coingecko_fallback(t, period_days)
                    if df is not None and not df.empty:
                        self._batch_cache[f"{t}|single"] = df
                        cg_loaded += 1
                if cg_loaded > 0:
                    print(f"    âœ… CoinGeckoåŠ è½½: {cg_loaded}/{len(crypto_candidates)}ä¸ªticker")
                loaded += cg_loaded

        # æ„å»ºåˆ†ç»„ç¼“å­˜ï¼ˆè®© download_prices å­é›†å‘½ä¸­æ›´é«˜æ•ˆï¼‰
        for group_name, group_tickers_str in self._preload_groups.items():
            group_tickers = group_tickers_str.split()
            group_dfs = {}
            for t in group_tickers:
                single_key = f"{t}|single"
                if single_key in self._batch_cache:
                    group_dfs[t] = self._batch_cache[single_key]
            if len(group_dfs) >= 2:
                merged = self._merge_to_multiindex(group_dfs)
                if merged is not None:
                    group_batch_key = f"{'|'.join(sorted(group_dfs.keys()))}|{period}|1d"
                    self._batch_cache[group_batch_key] = merged

        elapsed = time.time() - t0
        print(f"  ğŸ“¡ é¢„åŠ è½½å®Œæˆ ({elapsed:.1f}ç§’) | "
              f"AVè°ƒç”¨{self._stats['av_calls']}æ¬¡ | "
              f"ç¼“å­˜å‘½ä¸­{self._stats['av_cache_hits']}æ¬¡")
        return loaded > 0

    # â”€â”€â”€ FRED å®è§‚æ•°æ®å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def fetch_fred_series(self, series_id: str, observation_start: str = None,
                          limit: int = 10) -> Optional[List[Dict]]:
        """ä»FREDè·å–å•ä¸ªæ—¶é—´åºåˆ—çš„æœ€æ–°æ•°æ®"""
        if not FRED_API_KEY:
            return None

        fred_cache_key = f"{series_id}|{observation_start or ''}|{limit}"
        if fred_cache_key in self._fred_cache:
            return self._fred_cache[fred_cache_key]

        self._rate_limit('fred', FRED_CALL_DELAY)

        try:
            from fredapi import Fred
            fred = Fred(api_key=FRED_API_KEY)

            if observation_start:
                data = fred.get_series(series_id, observation_start=observation_start)
            else:
                start = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d')
                data = fred.get_series(series_id, observation_start=start)

            if data is not None and not data.empty:
                result = []
                for date, value in data.dropna().items():
                    result.append({
                        'date': date.strftime('%Y-%m-%d'),
                        'value': float(value)
                    })
                result = result[-limit:] if len(result) > limit else result
                self._fred_cache[fred_cache_key] = result
                self._stats['fred_calls'] += 1
                return result

        except ImportError:
            print("    âš ï¸ fredapiæœªå®‰è£… (pip install fredapi)")
        except Exception as e:
            print(f"    âš ï¸ FRED [{series_id}] è·å–å¤±è´¥: {e}")
            self._stats['errors'] += 1
        return None

    def fetch_fred_latest(self, series_id: str) -> Optional[float]:
        """è·å–FREDåºåˆ—çš„æœ€æ–°å€¼"""
        data = self.fetch_fred_series(series_id, limit=1)
        if data and len(data) > 0:
            return data[-1]['value']
        return None

    def fetch_macro_data(self) -> MacroData:
        """è·å–å®Œæ•´å®è§‚ç»æµæ•°æ®åŒ…ï¼ˆFREDä¼˜å…ˆï¼‰"""
        if self._macro_data is not None:
            return self._macro_data

        macro = MacroData(last_updated=datetime.now().strftime('%Y-%m-%d %H:%M'))

        if FRED_API_KEY:
            print("    ğŸ“Š ä»FREDè·å–å®è§‚æ•°æ®...")
            macro.fed_funds_rate = self.fetch_fred_latest('FEDFUNDS')
            macro.us10y_yield = self.fetch_fred_latest('DGS10')
            macro.us2y_yield = self.fetch_fred_latest('DGS2')
            macro.us2s10s_spread = self.fetch_fred_latest('T10Y2Y')
            macro.us3m10s_spread = self.fetch_fred_latest('T10Y3M')
            macro.hy_spread = self.fetch_fred_latest('BAMLH0A0HYM2')
            macro.cpi_yoy = self.fetch_fred_latest('CORESTICKM159SFRBATL')

            pce_hist = self.fetch_fred_series('PCEPILFE', limit=15)
            if pce_hist and len(pce_hist) >= 13:
                pce_now = pce_hist[-1]['value']
                pce_yr_ago = pce_hist[-13]['value']
                if pce_yr_ago > 0:
                    macro.core_pce = (pce_now - pce_yr_ago) / pce_yr_ago * 100
            elif pce_hist and len(pce_hist) >= 2:
                macro.core_pce = macro.cpi_yoy

            macro.unemployment = self.fetch_fred_latest('UNRATE')
            macro.initial_claims = self.fetch_fred_latest('ICSA')
            macro.gdp_growth = self.fetch_fred_latest('A191RL1Q225SBEA')
            macro.fed_balance_sheet = self.fetch_fred_latest('WALCL')
            macro.tga_balance = self.fetch_fred_latest('WTREGEN')
            macro.on_rrp = self.fetch_fred_latest('RRPONTSYD')

            if all(v is not None for v in [macro.fed_balance_sheet, macro.tga_balance, macro.on_rrp]):
                # WALCL (ç™¾ä¸‡ç¾å…ƒ) / 1000 â†’ åäº¿ç¾å…ƒ
                # WTREGEN (ç™¾ä¸‡ç¾å…ƒ) / 1000 â†’ åäº¿ç¾å…ƒ
                # RRPONTSYD (åäº¿ç¾å…ƒ) â†’ å·²æ˜¯åäº¿ç¾å…ƒ
                walcl_b = macro.fed_balance_sheet / 1000
                tga_b = macro.tga_balance / 1000
                rrp_b = macro.on_rrp
                macro.net_liquidity = walcl_b - tga_b - rrp_b

            macro.m2_supply = self.fetch_fred_latest('M2SL')
            macro.mortgage_rate_30y = self.fetch_fred_latest('MORTGAGE30US')
            macro.sofr = self.fetch_fred_latest('SOFR')
            macro.dxy_index = self.fetch_fred_latest('DTWEXBGS')

            macro.source = "FRED"

            fields = [macro.fed_funds_rate, macro.us10y_yield, macro.us2y_yield,
                      macro.us2s10s_spread, macro.hy_spread, macro.cpi_yoy,
                      macro.unemployment, macro.fed_balance_sheet, macro.net_liquidity]
            success = sum(1 for f in fields if f is not None)
            print(f"    âœ… FREDå®è§‚æ•°æ®: {success}/{len(fields)}é¡¹è·å–æˆåŠŸ")
            macro.raw_data = {k: v for k, v in self._fred_cache.items()}
        else:
            print("    âš ï¸ FRED_API_KEYæœªè®¾ç½®")
            macro.source = "unavailable"

        self._macro_data = macro
        return macro

    def fetch_fred_series_history(self, series_id: str, years: int = 1) -> Optional[List[Dict]]:
        """è·å–FREDåºåˆ—çš„å†å²æ•°æ®"""
        start = (datetime.now() - timedelta(days=years * 365)).strftime('%Y-%m-%d')
        return self.fetch_fred_series(series_id, observation_start=start, limit=500)

    def get_net_liquidity_trend(self, weeks: int = 12) -> Optional[List[Dict]]:
        """è·å–å‡€æµåŠ¨æ€§è¶‹åŠ¿"""
        if not FRED_API_KEY:
            return None

        start = (datetime.now() - timedelta(weeks=weeks)).strftime('%Y-%m-%d')
        walcl = self.fetch_fred_series('WALCL', observation_start=start, limit=50)
        tga = self.fetch_fred_series('WTREGEN', observation_start=start, limit=50)
        rrp = self.fetch_fred_series('RRPONTSYD', observation_start=start, limit=50)

        if not walcl:
            return None

        trend = []
        tga_dict = {d['date']: d['value'] for d in (tga or [])}
        rrp_dict = {d['date']: d['value'] for d in (rrp or [])}

        for w in walcl:
            date = w['date']
            w_val = w['value']
            t_val = tga_dict.get(date) or self._find_nearest(tga_dict, date)
            r_val = rrp_dict.get(date) or self._find_nearest(rrp_dict, date)
            if t_val is not None and r_val is not None:
                w_b = w_val / 1000
                t_b = t_val / 1000
                r_b = r_val
                net = w_b - t_b - r_b
                trend.append({'date': date, 'walcl': w_b, 'tga': t_b,
                              'rrp': r_b, 'net_liquidity': net})
        return trend if trend else None

    def _find_nearest(self, data_dict: dict, target_date: str) -> Optional[float]:
        """åœ¨æ—¥æœŸå­—å…¸ä¸­æ‰¾æœ€æ¥è¿‘çš„å€¼"""
        if not data_dict:
            return None
        target = datetime.strptime(target_date, '%Y-%m-%d')
        best_date, best_diff = None, timedelta(days=999)
        for d_str in data_dict:
            d = datetime.strptime(d_str, '%Y-%m-%d')
            diff = abs(d - target)
            if diff < best_diff:
                best_diff = diff
                best_date = d_str
        return data_dict.get(best_date) if best_diff <= timedelta(days=7) else None

    # â”€â”€â”€ AkShare ä¸­å›½å¸‚åœºæ•°æ®å±‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def fetch_china_market_data(self) -> ChinaMarketData:
        """è·å–ä¸­å›½å¸‚åœºæ•°æ®"""
        if self._china_data is not None:
            return self._china_data

        china = ChinaMarketData(last_updated=datetime.now().strftime('%Y-%m-%d %H:%M'))

        try:
            import akshare as ak
            print("    ğŸ‡¨ğŸ‡³ ä»AkShareè·å–ä¸­å›½å¸‚åœºæ•°æ®...")

            try:
                self._rate_limit('akshare', AKSHARE_CALL_DELAY)
                flow_df = ak.stock_hsgt_fund_flow_summary_em()
                if flow_df is not None and not flow_df.empty:
                    north_rows = flow_df[flow_df['èµ„é‡‘æ–¹å‘'] == 'åŒ—å‘']
                    if not north_rows.empty:
                        china.northbound_flow = float(north_rows['æˆäº¤å‡€ä¹°é¢'].sum())
                        print(f"      åŒ—å‘èµ„é‡‘: {china.northbound_flow:+.1f}äº¿å…ƒ")
                    south_rows = flow_df[flow_df['èµ„é‡‘æ–¹å‘'] == 'å—å‘']
                    if not south_rows.empty:
                        china.southbound_flow = float(south_rows['æˆäº¤å‡€ä¹°é¢'].sum())
                        print(f"      å—å‘èµ„é‡‘: {china.southbound_flow:+.1f}äº¿å…ƒ")
                    china.raw_data['hsgt_flow'] = flow_df.to_dict('records')
            except Exception as e:
                print(f"      âš ï¸ æ²ªæ·±æ¸¯é€šèµ„é‡‘è·å–å¤±è´¥: {e}")

            try:
                self._rate_limit('akshare', AKSHARE_CALL_DELAY)
                ah_df = ak.stock_zh_ah_spot_em()
                if ah_df is not None and not ah_df.empty and 'æº¢ä»·' in ah_df.columns:
                    avg_premium = ah_df['æº¢ä»·'].mean()
                    china.ah_premium_index = 100 + avg_premium
                    print(f"      AHæº¢ä»·æŒ‡æ•°(ä¼°ç®—): {china.ah_premium_index:.1f}")
            except Exception as e:
                print(f"      âš ï¸ AHæº¢ä»·æŒ‡æ•°è·å–å¤±è´¥: {e}")

            try:
                self._rate_limit('akshare', AKSHARE_CALL_DELAY)
                margin_df = ak.stock_margin_account_info()
                if margin_df is not None and not margin_df.empty:
                    latest = margin_df.iloc[-1]
                    for col in margin_df.columns:
                        if 'ä½™é¢' in str(col) and 'èèµ„' in str(col):
                            china.margin_balance = float(latest[col])
                            print(f"      ä¸¤èä½™é¢: {china.margin_balance:,.0f}äº¿å…ƒ")
                            break
            except Exception as e:
                print(f"      âš ï¸ èèµ„èåˆ¸æ•°æ®è·å–å¤±è´¥: {e}")

            try:
                self._rate_limit('akshare', AKSHARE_CALL_DELAY)
                shibor_df = ak.macro_china_shibor_all()
                if shibor_df is not None and not shibor_df.empty:
                    latest = shibor_df.iloc[-1]
                    for col in shibor_df.columns:
                        if 'éš”å¤œ' in str(col) or 'O/N' in str(col):
                            china.shibor_overnight = float(latest[col])
                            print(f"      SHIBORéš”å¤œ: {china.shibor_overnight:.4f}%")
                            break
            except Exception as e:
                print(f"      âš ï¸ SHIBORè·å–å¤±è´¥: {e}")

            # äººæ°‘å¸æ±‡ç‡ â€” ä¼˜å…ˆç”¨AV
            try:
                fx_data = self._av_get_fx_daily('USD', 'CNY')
                if fx_data:
                    fx_ts = fx_data.get('Time Series FX (Daily)', {})
                    if fx_ts:
                        latest_date = list(fx_ts.keys())[0]
                        china.cny_usd = float(fx_ts[latest_date]['4. close'])
                        print(f"      ç¾å…ƒ/äººæ°‘å¸(AV): {china.cny_usd:.4f}")
            except Exception:
                pass

            china.source = "AkShare"
            success = sum(1 for v in [china.northbound_flow, china.southbound_flow,
                                       china.ah_premium_index, china.margin_balance,
                                       china.shibor_overnight, china.cny_usd] if v is not None)
            print(f"    âœ… AkShareä¸­å›½å¸‚åœº: {success}/6é¡¹è·å–æˆåŠŸ")

        except ImportError:
            print("    âš ï¸ akshareæœªå®‰è£… (pip install akshare)")
            china.source = "unavailable"
        except Exception as e:
            print(f"    âš ï¸ AkShareå¼‚å¸¸: {e}")
            china.source = "unavailable"

        self._china_data = china
        return china

    # â”€â”€â”€ Alpha Vantage æŠ€æœ¯æŒ‡æ ‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def fetch_av_indicator(self, symbol: str, indicator: str = 'RSI',
                           interval: str = 'daily', time_period: int = 14) -> Optional[List[Dict]]:
        """ä»Alpha Vantageè·å–æŠ€æœ¯æŒ‡æ ‡"""
        if not ALPHA_VANTAGE_KEY:
            return None

        cache_key = f"av_{symbol}_{indicator}_{time_period}"
        if cache_key in self._av_cache:
            return self._av_cache[cache_key]

        data = self._av_request({
            'function': indicator,
            'symbol': symbol,
            'interval': interval,
            'time_period': time_period,
            'series_type': 'close',
        })

        if data:
            result_key = [k for k in data.keys() if 'Technical Analysis' in k]
            if result_key:
                ts = data[result_key[0]]
                result = []
                for date, values in list(ts.items())[:30]:
                    point = {'date': date}
                    point.update({k: float(v) for k, v in values.items()})
                    result.append(point)
                result.reverse()
                self._av_cache[cache_key] = result
                return result
        return None

    # â”€â”€â”€ å…¨çƒæŒ‡æ•°å®æ—¶æ•°æ®ï¼ˆAkShareä¸œæ–¹è´¢å¯Œï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def get_global_index_spot(self) -> dict:
        """
        è·å–å…¨çƒä¸»è¦æŒ‡æ•°çš„çœŸå®ç‚¹ä½æ•°æ®ï¼ˆéETFä»£ç†ï¼‰
        è¿”å›: {ticker: {'price': float, 'change': float, 'prev_close': float}} 
        """
        if hasattr(self, '_global_index_cache') and self._global_index_cache:
            return self._global_index_cache

        result = {}
        try:
            import akshare as ak
            self._rate_limit('akshare', AKSHARE_CALL_DELAY)
            df = ak.index_global_spot_em()
            if df is not None and not df.empty:
                # å»ºç«‹ AkShareä»£ç  â†’ è¡Œæ•°æ® çš„æ˜ å°„
                ak_data = {}
                for _, row in df.iterrows():
                    ak_data[str(row['ä»£ç '])] = row

                # å°† ticker â†’ AkShareä»£ç  æ˜ å°„è½¬æ¢ä¸ºç»“æœ
                for ticker, ak_code in INDEX_TO_AKSHARE_GLOBAL.items():
                    if ak_code in ak_data:
                        row = ak_data[ak_code]
                        price = float(row['æœ€æ–°ä»·']) if row['æœ€æ–°ä»·'] else 0
                        prev_close = float(row['æ˜¨æ”¶ä»·']) if row['æ˜¨æ”¶ä»·'] else 0
                        change_pct = float(row['æ¶¨è·Œå¹…']) if row['æ¶¨è·Œå¹…'] else 0
                        if price > 0:
                            result[ticker] = {
                                'price': price,
                                'change': change_pct,
                                'prev_close': prev_close,
                            }

                print(f"    âœ… AkShareå…¨çƒæŒ‡æ•°å®æ—¶æ•°æ®: {len(result)}/{len(INDEX_TO_AKSHARE_GLOBAL)}ä¸ª")
        except Exception as e:
            print(f"    âš ï¸ AkShareå…¨çƒæŒ‡æ•°è·å–å¤±è´¥: {e}")

        # â•â•â• è¡¥å……: é€šè¿‡Google Financeè·å–AkShareç¼ºå¤±çš„æŒ‡æ•°ï¼ˆç½—ç´ 2000ã€VIXï¼‰â•â•â•
        for ticker, (gf_symbol, gf_exchange) in INDEX_GOOGLE_FINANCE_FALLBACK.items():
            if ticker not in result:
                try:
                    gf_data = self._fetch_google_finance_index(gf_symbol, gf_exchange)
                    if gf_data:
                        result[ticker] = gf_data
                        print(f"    âœ… Google Financeè¡¥å……: {gf_symbol} = {gf_data['price']:.2f} ({gf_data['change']:+.2f}%)")
                except Exception as e:
                    print(f"    âš ï¸ Google Financeè·å–{gf_symbol}å¤±è´¥: {e}")

        self._global_index_cache = result
        return result

    def _fetch_google_finance_index(self, symbol: str, exchange: str) -> dict:
        """
        ä»Google Financeç½‘é¡µæŠ“å–æŒ‡æ•°çœŸå®ä»·æ ¼
        è¿”å›: {'price': float, 'change': float, 'prev_close': float} æˆ– None
        """
        import urllib.request
        import re
        import ssl

        url = f"https://www.google.com/finance/quote/{symbol}:{exchange}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Accept-Language': 'en-US,en;q=0.9',
        }
        ctx = ssl.create_default_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE

        req = urllib.request.Request(url, headers=headers)
        with urllib.request.urlopen(req, timeout=10, context=ctx) as resp:
            html = resp.read().decode('utf-8', errors='ignore')

        price = None
        prev_close = None

        # æ–¹æ³•1: data-last-price å±æ€§ï¼ˆæœ€å¯é ï¼‰
        m = re.search(r'data-last-price="([0-9.,]+)"', html)
        if m:
            price = float(m.group(1).replace(',', ''))

        # æ–¹æ³•2: YMlKec fxKbKc classï¼ˆé¡µé¢æ˜¾ç¤ºä»·æ ¼ï¼‰
        if price is None:
            m = re.search(r'class="YMlKec fxKbKc"[^>]*>([0-9,]+\.?\d*)', html)
            if m:
                price = float(m.group(1).replace(',', ''))

        # æ–¹æ³•3: Previous close
        m = re.search(r'Previous close.*?([0-9,]+\.\d+)', html, re.DOTALL)
        if m:
            prev_close = float(m.group(1).replace(',', ''))

        if price and price > 0:
            change_pct = 0
            if prev_close and prev_close > 0:
                change_pct = (price - prev_close) / prev_close * 100
            else:
                prev_close = price
            return {
                'price': price,
                'change': change_pct,
                'prev_close': prev_close,
            }
        return None

    # â”€â”€â”€ æ–°æµªå¤–æ±‡/å•†å“å®æ—¶æ•°æ® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # æ–°æµªå¤–æ±‡/å•†å“ç¬¦å·æ˜ å°„
    # ETF ticker â†’ (æ–°æµªç¬¦å·, æ˜¾ç¤ºåç§°, ä»·æ ¼å•ä½, æ•°æ®ç±»å‹)
    # æ•°æ®ç±»å‹: 'fx' = å¤–æ±‡(å­—æ®µæ ¼å¼ä¸åŒäº 'futures')
    SINA_REALTIME_MAP = {
        'UUP': ('DINIW', 'ç¾å…ƒæŒ‡æ•°', '', 'fx'),
        'FXY': ('USDJPY', 'ç¾å…ƒ/æ—¥å…ƒ', '', 'fx'),
        'FXE': ('EURUSD', 'æ¬§å…ƒ/ç¾å…ƒ', '', 'fx'),
        'GLD': ('hf_GC', 'é»„é‡‘', 'ç¾å…ƒ/ç›å¸', 'futures'),
        'SLV': ('hf_SI', 'ç™½é“¶', 'ç¾å…ƒ/ç›å¸', 'futures'),
    }

    def fetch_sina_realtime(self, symbols: list) -> dict:
        """
        ä»æ–°æµªè´¢ç»è·å–å¤–æ±‡/å•†å“å®æ—¶æ•°æ®
        Args:
            symbols: æ–°æµªç¬¦å·åˆ—è¡¨ï¼Œå¦‚ ['DINIW', 'USDJPY', 'hf_GC']
        Returns:
            {symbol: {'price': float, 'change': float, 'prev_close': float, 'name': str}}
        """
        import urllib.request
        import ssl
        import re

        if not symbols:
            return {}

        ctx = ssl.create_default_context()
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE

        result = {}
        try:
            symbols_str = ','.join(symbols)
            url = f'https://hq.sinajs.cn/list={symbols_str}'
            req = urllib.request.Request(url, headers={
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)',
                'Referer': 'https://finance.sina.com.cn/',
            })
            resp = urllib.request.urlopen(req, context=ctx, timeout=10).read().decode('gbk', errors='ignore')

            for line in resp.strip().split('\n'):
                m = re.match(r'var hq_str_(\w+)="(.*)";', line)
                if not m or not m.group(2):
                    continue
                key = m.group(1)
                parts = m.group(2).split(',')

                try:
                    if key.startswith('hf_'):
                        # å¤–ç›˜æœŸè´§æ ¼å¼: æœ€æ–°ä»·,,å–1,ä¹°1,æœ€é«˜,æœ€ä½,æ—¶é—´,å‰ç»“ç®—,å¼€ç›˜,...,æ—¥æœŸ,å“å
                        price = float(parts[0])
                        prev_close = float(parts[7]) if parts[7] else 0
                        name = parts[13] if len(parts) > 13 else key
                    else:
                        # å¤–æ±‡æ ¼å¼: æ—¶é—´,ä¹°å…¥ä»·,å–å‡ºä»·,æœ€æ–°ä»·,æˆäº¤é‡,æ˜¨æ”¶,æœ€é«˜,æœ€ä½,...,åç§°,æ—¥æœŸ
                        price = float(parts[1]) if parts[1] and float(parts[1]) > 0 else float(parts[3])
                        prev_close = float(parts[5]) if parts[5] else 0
                        name = parts[9] if len(parts) > 9 else key

                    if price > 0:
                        change_pct = (price - prev_close) / prev_close * 100 if prev_close > 0 else 0
                        result[key] = {
                            'price': price,
                            'change': round(change_pct, 2),
                            'prev_close': prev_close,
                            'name': name,
                        }
                except (ValueError, IndexError):
                    continue

        except Exception as e:
            print(f"    âš ï¸ æ–°æµªå¤–æ±‡/å•†å“æ•°æ®è·å–å¤±è´¥: {e}")

        return result

    def get_forex_commodity_realtime(self) -> dict:
        """
        è·å–å¤–æ±‡å’Œå•†å“çœŸå®ä»·æ ¼ï¼ˆæ›¿ä»£ETFä»£ç†ï¼‰
        Returns:
            {etf_ticker: {'price': float, 'change': float, 'name': str, 'unit': str}}
            ä¾‹å¦‚: {'UUP': {'price': 97.61, 'change': -0.09, 'name': 'ç¾å…ƒæŒ‡æ•°', 'unit': ''}}
        """
        if hasattr(self, '_forex_commodity_cache') and self._forex_commodity_cache:
            return self._forex_commodity_cache

        # æ”¶é›†éœ€è¦æŸ¥è¯¢çš„æ–°æµªç¬¦å·
        sina_symbols = []
        etf_to_sina = {}
        for etf_ticker, (sina_sym, display_name, unit, dtype) in self.SINA_REALTIME_MAP.items():
            sina_symbols.append(sina_sym)
            etf_to_sina[etf_ticker] = (sina_sym, display_name, unit)

        sina_data = self.fetch_sina_realtime(sina_symbols)

        result = {}
        for etf_ticker, (sina_sym, display_name, unit) in etf_to_sina.items():
            if sina_sym in sina_data:
                d = sina_data[sina_sym]
                result[etf_ticker] = {
                    'price': d['price'],
                    'change': d['change'],
                    'name': display_name,
                    'unit': unit,
                }

        if result:
            print(f"    âœ… æ–°æµªå¤–æ±‡/å•†å“å®æ—¶æ•°æ®: {len(result)}/{len(self.SINA_REALTIME_MAP)}ä¸ª")
        self._forex_commodity_cache = result
        return result

    # â”€â”€â”€ Fear & Greed Index â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def get_fear_greed_index(self) -> dict:
        """è·å–ææƒ§è´ªå©ªæŒ‡æ•°"""
        if self._fear_greed is not None:
            return self._fear_greed

        try:
            import fear_and_greed
            fgi = fear_and_greed.get()
            self._fear_greed = {
                'value': fgi.value,
                'description': fgi.description,
            }
        except Exception as e:
            print(f"    âš ï¸ ææƒ§è´ªå©ªæŒ‡æ•°è·å–å¤±è´¥: {e}")
            self._fear_greed = {'value': 50, 'description': 'Neutral (è·å–å¤±è´¥)'}

        return self._fear_greed

    # â”€â”€â”€ æŠ€æœ¯æŒ‡æ ‡è®¡ç®—ï¼ˆæœ¬åœ°ï¼‰â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    @staticmethod
    def calc_rsi(prices, period: int = 14) -> float:
        import numpy as np
        if prices is None or len(prices) < period + 1:
            return 50.0
        deltas = np.diff(prices)
        gains = np.where(deltas > 0, deltas, 0)
        losses = np.where(deltas < 0, -deltas, 0)
        avg_gain = np.mean(gains[-period:])
        avg_loss = np.mean(losses[-period:])
        if avg_loss == 0:
            return 100.0
        rs = avg_gain / avg_loss
        return 100.0 - (100.0 / (1.0 + rs))

    @staticmethod
    def calc_ma(prices, period: int) -> float:
        if prices is None or len(prices) < period:
            return float(prices[-1]) if prices is not None and len(prices) > 0 else 0
        return sum(float(p) for p in prices[-period:]) / period

    @staticmethod
    def calc_ema(prices, period: int) -> float:
        import numpy as np
        if prices is None or len(prices) < period:
            return float(prices[-1]) if prices is not None and len(prices) > 0 else 0
        multiplier = 2 / (period + 1)
        ema = float(prices[0])
        for p in prices[1:]:
            ema = (float(p) - ema) * multiplier + ema
        return ema

    @staticmethod
    def calc_macd(prices, fast: int = 12, slow: int = 26, signal: int = 9) -> Tuple[float, float, float]:
        if prices is None or len(prices) < slow + signal:
            return 0.0, 0.0, 0.0

        def _ema(data, period):
            multiplier = 2 / (period + 1)
            ema_val = float(data[0])
            ema_arr = [ema_val]
            for p in data[1:]:
                ema_val = (float(p) - ema_val) * multiplier + ema_val
                ema_arr.append(ema_val)
            return ema_arr

        ema_fast = _ema(prices, fast)
        ema_slow = _ema(prices, slow)
        macd_line = [f - s for f, s in zip(ema_fast, ema_slow)]
        signal_line = _ema(macd_line, signal)
        histogram = macd_line[-1] - signal_line[-1]
        return macd_line[-1], signal_line[-1], histogram

    @staticmethod
    def weekly_change(closes) -> float:
        if closes is None or len(closes) < 5:
            return 0.0
        curr, prev = float(closes[-1]), float(closes[-5])
        return (curr - prev) / prev if prev != 0 else 0.0

    @staticmethod
    def daily_change(closes) -> float:
        if closes is None or len(closes) < 2:
            return 0.0
        curr, prev = float(closes[-1]), float(closes[-2])
        return (curr - prev) / prev if prev != 0 else 0.0

    @staticmethod
    def monthly_change(closes) -> float:
        if closes is None or len(closes) < 21:
            return 0.0
        curr, prev = float(closes[-1]), float(closes[-21])
        return (curr - prev) / prev if prev != 0 else 0.0

    @staticmethod
    def calc_volatility(prices, period: int = 20) -> float:
        import numpy as np
        if prices is None or len(prices) < period + 1:
            return 0.0
        returns = np.diff(np.log(prices[-period-1:].astype(float)))
        return float(np.std(returns) * np.sqrt(252))

    @staticmethod
    def calc_drawdown(prices) -> float:
        import numpy as np
        if prices is None or len(prices) < 2:
            return 0.0
        peak = float(np.max(prices))
        current = float(prices[-1])
        return (current - peak) / peak if peak > 0 else 0.0

    # â”€â”€â”€ ç»Ÿè®¡ä¸è¯Šæ–­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def get_stats(self) -> dict:
        return {
            **self._stats,
            'av_rate_limited': self._av_rate_limited,
            'av_consecutive_limits': self._av_consecutive_limits,
            'cache_size': {
                'batch_cache': len(self._batch_cache),
                'info_cache': len(self._info_cache),
                'fred_cache': len(self._fred_cache),
                'av_cache': len(self._av_cache),
            },
            'data_sources': {
                'alpha_vantage': 'rate_limited' if self._av_rate_limited else ('active' if ALPHA_VANTAGE_KEY else 'inactive'),
                'fred': 'active' if FRED_API_KEY else 'inactive',
                'akshare': self._check_akshare_available(),
                'yfinance': 'unavailable' if self._yf_available is False else ('active' if self._yf_available else 'fallback'),
                'coingecko': 'active',
                'fear_and_greed': 'active',
            }
        }

    def _check_akshare_available(self) -> str:
        try:
            import akshare
            return 'active'
        except ImportError:
            return 'not_installed'

    def print_diagnostics(self):
        stats = self.get_stats()
        print(f"\n{'='*50}")
        print(f"  ğŸ“Š æ•°æ®æºè¯Šæ–­æŠ¥å‘Š")
        print(f"{'='*50}")
        print(f"  Alpha Vantageè°ƒç”¨: {stats['av_calls']}æ¬¡ | ç¼“å­˜å‘½ä¸­: {stats['av_cache_hits']}æ¬¡")
        if stats.get('av_rate_limited'):
            print(f"  ğŸš« AVå…¨å±€é™æµå·²è§¦å‘ï¼ˆè¿ç»­{stats['av_consecutive_limits']}æ¬¡ï¼‰")
        print(f"  yfinanceé™çº§è°ƒç”¨: {stats['yf_downloads']}æ¬¡")
        print(f"  FREDè°ƒç”¨: {stats['fred_calls']}æ¬¡")
        print(f"  AkShareè°ƒç”¨: {stats['akshare_calls']}æ¬¡")
        print(f"  é”™è¯¯æ€»æ•°: {stats['errors']}æ¬¡")
        print(f"  ç¼“å­˜å¤§å°: batch={stats['cache_size']['batch_cache']} "
              f"info={stats['cache_size']['info_cache']} "
              f"fred={stats['cache_size']['fred_cache']} "
              f"av={stats['cache_size']['av_cache']}")
        print(f"\n  æ•°æ®æºçŠ¶æ€:")
        for src, status in stats['data_sources'].items():
            icon = 'âœ…' if status == 'active' else ('âš ï¸' if status in ('not_installed', 'fallback', 'rate_limited') else 'âŒ')
            print(f"    {icon} {src}: {status}")
        print(f"{'='*50}\n")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¾¿æ·å‡½æ•°ï¼ˆå…¼å®¹æ—§ç‰ˆä»£ç ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_global_manager: Optional[DataSourceManager] = None

def get_manager(config: dict = None) -> DataSourceManager:
    global _global_manager
    if _global_manager is None:
        _global_manager = DataSourceManager(config)
    return _global_manager

def reset_manager():
    global _global_manager
    _global_manager = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è‡ªæµ‹å…¥å£
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    print("ğŸ” æ•°æ®æºç®¡ç†å™¨ v2.0 è‡ªæµ‹ï¼ˆAlpha Vantageä¼˜å…ˆï¼‰...\n")

    dm = DataSourceManager()

    print("--- æµ‹è¯•1: AVæ—¥çº¿ä¸‹è½½ ---")
    data = dm.download_prices("AAPL MSFT", period="5d")
    if data is not None:
        closes = dm.get_closes(data, 'AAPL')
        print(f"  AAPLæœ€æ–°æ”¶ç›˜: ${float(closes[-1]):,.2f}" if closes is not None else "  AAPL: æ— æ•°æ®")
    else:
        print("  âŒ ä¸‹è½½å¤±è´¥")

    print("\n--- æµ‹è¯•2: ç¼“å­˜éªŒè¯ ---")
    data2 = dm.download_prices("AAPL MSFT", period="5d")
    print(f"  ç¼“å­˜å‘½ä¸­: {dm._stats['av_cache_hits']}")

    print("\n--- æµ‹è¯•3: åŠ å¯†è´§å¸ ---")
    btc_data = dm.download_prices("BTC-USD", period="5d")
    if btc_data is not None:
        btc_closes = dm.get_closes(btc_data, 'BTC-USD')
        print(f"  BTCæœ€æ–°: ${float(btc_closes[-1]):,.0f}" if btc_closes is not None else "  BTC: æ— æ•°æ®")

    print("\n--- æµ‹è¯•4: å…¬å¸åŸºæœ¬é¢ ---")
    info = dm.get_ticker_info('AAPL')
    if info:
        print(f"  {info.get('shortName', '?')} PE={info.get('forwardPE', '?')} ROE={info.get('returnOnEquity', '?')}")

    print("\n--- æµ‹è¯•5: FREDå®è§‚æ•°æ® ---")
    if FRED_API_KEY:
        macro = dm.fetch_macro_data()
        print(f"  è”é‚¦åŸºé‡‘åˆ©ç‡: {macro.fed_funds_rate}")
        print(f"  10å¹´æœŸæ”¶ç›Šç‡: {macro.us10y_yield}")

    print("\n--- æµ‹è¯•6: Fear & Greed ---")
    fgi = dm.get_fear_greed_index()
    print(f"  F&G: {fgi['value']} ({fgi['description']})")

    dm.print_diagnostics()
    print("âœ… è‡ªæµ‹å®Œæˆ")
